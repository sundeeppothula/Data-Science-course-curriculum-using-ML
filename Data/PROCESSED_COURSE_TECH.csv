,Course Name,Course Description,Keywords,Concepts,Technical Skills,Soft Skills,Coding Skills
0,NUvention Analytics,"NUvention: AnalyticsåÊis a unique interdisciplinary course being designed to create opportunities for students to create new analytics technologies and then build businesses around their innovations. This one-quarter class is conceived by students within the Engineering, Business, Law, Communications and other schools across campus along with the assistance of an Advisory board and the Farley Center for Entrepreneurship and Innovation. The course is built around projects, so an advisory board will keep track of the projects, giving its expert advice in order to ensure a proper product-market alignment.","['new analytics technologies', 'unique interdisciplinary course', 'proper product-market alignment', 'advisory board', 'one-quarter class', 'Farley Center', 'expert advice']","['Entrepreneurship', 'Innovation', 'Real estate', 'Technology', 'Business', 'Joseph Schumpeter', 'Design', 'Education', 'Invention', 'Creativity', 'Corporation', 'Economic growth', 'Economics', 'Engineering', 'Creative problem solving', 'Advice', 'Management']",[],[],[]
1,Computer Simulation for Risk and Operations Analysis,"This is a hands-on course on computer simulation of business, service, and manufacturing systems that are subject to uncertainty or risk. Spreadsheet simulation using @Risk and system simulation using Arena will be covered. Upon completion of the course students will be able to develop complex simulation models, design the simulation experiment to be run on the model, and analyze and interpret the results. Managing simulation projects is also addressed.","['complex simulation models', 'hands-on course', 'Spreadsheet simulation', 'simulation experiment', 'simulation projects', 'uncertainty', 'risk', 'completion', 'analyze', 'Arena', 'business', 'service', 'systems', 'students', 'design']","['Computer graphics', 'Computer simulation', 'Operations research', 'Management', 'Systems engineering', 'Risk management', 'System']","['simulation', 'simulation', 'simulation', 'simulation', 'simulation', 'simulation']",[],[]
2,Everything Starts with Data,This course provides aåÊfundamentalåÊpractical coverage of analytics. The focus of the course is to expose you to challenges and opportunities in analytics through a couple of projects. We will be using the tools that you learned in the boot camp. The majority of the material and lecturing will be computer based.åÊ,"['boot camp', 'aåÊfundamentalåÊpractical coverage', 'analytics', 'lecturing', 'majority', 'couple', 'challenges', 'course', 'focus', 'opportunities', 'projects', 'tools', 'material']","['Mac OS X', 'Focus']",[],[],[]
3,Predictive Analytics I,"This course covers linear parametric methods of regression and classification. They include multiple regression, binary logistic regression, multinomial (nominal and ordinal) logistic regression, discriminant analysis and generalized linear models. R software is used to apply the methods to real data sets. A large data analysis group project required.","['binary logistic regression', 'linear parametric methods', 'generalized linear models', 'multiple regression', 'analysis group project', 'real data sets', 'discriminant analysis']","['Regression analysis', 'Logistic regression', 'Generalized linear model', 'Linear regression', 'Econometrics', 'Logit', 'Multivariate adaptive regression splines', 'Ordinary least squares', 'Multinomial logit', 'Censored regression model', 'Georg Cantor', 'Statistics', 'Errors and residuals in statistics', 'Parametric statistics', 'Iteratively reweighted least squares', 'Probit model', 'Segmented regression', 'Forecasting', 'Statistical inference', '0', 'Multiplication', 'Natural number']","['regression', 'regression', 'regression', 'regression']",[],['R']
4,Business Communication & Analytics Consulting,"In this class, we examine project management, business communication, and client interaction best practices that support the MSiA practicum and capstone projects. Special emphasis is given to translating or relating the analytical output of projects to the vocabulary and expectations of business functions in marketing, operations, and finance. We examine the best practices in managing client / employer expectations in the analytical environment. This provides students with the tools to successfully navigate the challenges of leading analytical projects while developing top-notch client-facing skills for their careers.","['interaction best practices', 'top-notch client-facing skills', 'MSiA practicum', 'employer expectations', 'capstone projects', 'project management', 'business communication', 'Special emphasis', 'analytical output', 'business functions', 'analytical environment', 'analytical projects']","['Management', 'Project management', 'Leadership', 'Project', 'Economics', 'Business', 'Plan', 'Communication', 'Cone of Uncertainty', 'Best practice', 'Marketing']",[],[],[]
5,Data Visualization,"A variety of data is being generated by businesses, government entities, and human activities at increasing rates and complexity. The goal of this course is to expose students to key design principles and techniques that can increase the understanding of complex data, and gain valuable insights for the data. Good visualizations present a visual interpretation of the data and also improve comprehension, communication, and decision making. Concepts, techniques, and methods for creating effective data visualizations will be covered. The course will also have a focus on how to present information clearly and effectively.","['gain valuable insights', 'effective data visualizations', 'key design principles', 'Good visualizations', 'government entities', 'human activities', 'visual interpretation', 'decision making', 'complex data', 'course', 'techniques', 'comprehension', 'complexity', 'variety', 'businesses', 'rates', 'goal', 'students', 'understanding', 'focus', 'information', 'communication']","['Cognition', 'Complexity', 'Variety', 'Abstraction', 'Decision making', 'Data', 'Business']",[],[],[]
6,Business Value from Analytics in the Digital Age,"In this class, we examine the role of the analytical function in various enterprises. Through leveraging real-world cases, we discover how a data scientist can be more impactful to the enterprise. Specifically, we study the role and structure of analytical teams. Students examine the return on investment, technical requirements, and strategic impacts of leading and operating an analytics team in the enterprise. We also investigate data monetization strategies for data rich firms. Specific emphasis is given to developing the leadership perspective on becoming the Chief Data Officer.","['data monetization strategies', 'Chief Data Officer', 'data rich firms', 'real-world cases', 'various enterprises', 'analytical function', 'strategic impacts', 'data scientist', 'analytics team', 'technical requirements', 'analytical teams', 'Specific emphasis', 'leadership perspective', 'role', 'return']","['Starship Enterprise', 'Sociology', 'Investment', 'Rate of return', 'Star Trek: The Next Generation', 'Star Trek: First Contact', 'Subroutine', 'Starfleet', 'Net present value', 'Borg', 'Hero', 'The Return', 'Strategy', 'Leadership', 'Team', 'Positive psychology', 'Star Trek: Enterprise', 'The A-Team', 'Tribal chief', 'Internal rate of return']",[],['team'],[]
7,Introduction to Databases & Information Retrieval,"The main goal of this course is to expose the students to the fundamentals of the Data Management and Database Systems in general and, more specifically, to Database Design and Querying, providing a balance between the breadth and the depth.","['main goal', 'Data Management', 'Database Systems', 'Database Design', 'breadth', 'Querying', 'fundamentals', 'balance', 'depth']",[],"['Database', 'Database']",['Management'],[]
8,Text Analytics,"This course will explore techniques to analyze unstructured text such as that found in emails, text messages, conversation transcripts, web pages, books,åÊscientific journals, etc. The course strives to offer a balance between breadth and depth, presenting both an overview of the field as well as some insight intoåÊthe mathematical underpinning of a few representative techniques.","['conversation transcripts', 'unstructured text', 'mathematical underpinning', 'web pages', 'books,åÊscientific journals', 'text messages', 'representative techniques', 'breadth', 'emails', 'course', 'balance', 'depth', 'insight', 'overview']","['Mobile phone', 'Web browser', 'Text messaging', 'World Wide Web', 'Breadth-first search']",['unstructured'],[],[]
9,Predictive Analytics II,"Non-parametric regression and classification, principal components analysis and dimension reduction, time series, and quality control methods.","['Non-parametric regression', 'principal components analysis', 'dimension reduction', 'quality control methods', 'time series']","['Singular value decomposition', 'Quality control', 'Nonparametric regression', 'Singular spectrum analysis', 'Management', 'Data analysis', 'Principal component analysis']",['regression'],[],[]
10,Data Mining,"Clustering (k-means, partitioning), association rules, factor analysis, scale development, and survival analysis.","['factor analysis', 'survival analysis', 'association rules', 'k-means', 'scale development']","['Principal component analysis', 'Statistics', 'Psychometrics', 'Educational psychology', 'Factor analysis']",['Clustering'],[],[]
11,Intro to Java & Python Programming,"The main objective of this course is to introduce students to the various capabilities of the Java & Python programming languages. In addition to this theme, students will be exposed to different techniques of software engineering (from the perspective of design and code organization) and broader programming principles, as well as the link(s) between data organization and algorithm implementation.","['Python programming languages', 'broader programming principles', 'main objective', 'algorithm implementation', 'various capabilities', 'different techniques', 'software engineering', 'code organization', 'data organization', 'addition', 'students', 'course', 'Java', 'theme', 'perspective', 'design']","['Programming language', 'Computer program', 'C', 'Java', 'Computer', 'Software engineering', 'Computer programming', 'Object-oriented programming', 'Scripting language', 'Comparison of programming languages', 'Programming paradigm', 'Programmer', 'Algorithm', 'Python', 'Exception handling', 'Bytecode', 'Design', 'Regular expression', 'Ruby', 'Language', 'Functional programming', 'Source code', 'Jython', 'Computer science', 'Engineering', 'Class', 'Perl', 'Interpreter', 'Modula-3', 'Groovy', 'D', 'ECMAScript', 'Haskell', 'Cross-platform', 'Java Virtual Machine', 'Imperative programming', 'The Various']","['programming', 'programming']",[],"['Java', 'Python']"
12,Introduction to Data Management for Business Intelligence,"This course is a continuation of MSiA 490 (Introduction to Data Management) and will focus on exploring the management of a subset of the five VÛªs[1] åÊof the big data, in the context of improving the decision-making capabilities in business intelligence. Specifically, the course will accentuate the Volume and Velocity (and, in an implicit manner, the other three VÛªs).","['implicit manner', 'decision-making capabilities', 'business intelligence', 'big data', 'Data Management', 'MSiA', 'continuation', 'subset', 'course', 'V\x89Ûªs', 'Velocity', 'context', 'Introduction']","['Business intelligence', 'Data management', 'Management', 'Strategic management', 'Data']",['big data'],['Management'],[]
13,Analytics for Big Data,"This course covers a variety of topics and tools in big data. Most of the topics are about the Hadoop ecosystem, however select databases outside of Hadoop will also be considered.","['Hadoop ecosystem', 'big data', 'topics', 'course', 'variety', 'tools']","['Computer program', 'Music magazines']",['big data'],[],"['Hadoop', 'Hadoop']"
14,Deep Learning,"Many challenging problems in diverse areas such as computer vision, speech recognition, and machine language translation have recently made great progress by using an emerging technology called deep learning. At its core, deep learning is inspired by a simplified model of how the human brain works by building effective hierarchical representations of complex data. This course will explore applications and theory relevant to problem solving using deep learning. By the end of this course, students will gain intuition about how to apply various techniques judiciously and how to evaluate success. Students will also gain deeper insight into why certain techniques may work or fail for certain kinds of problems.ÛÜ","['deep learning', 'machine language translation', 'human brain works', 'challenging problems', 'hierarchical representations', 'diverse areas', 'great progress', 'speech recognition', 'certain kinds', 'deeper insight', 'certain techniques', 'complex data', 'various techniques', 'course', 'students', 'intuition', 'vision', 'technology', 'core', 'model', 'applications', 'theory', 'end']","['Problem solving', 'Brain', 'Language', 'Computer program', 'Human brain', 'Problem', 'Programming language', 'Computer', 'Machine translation', 'Cerebellum', 'Translation', 'Education']","['deep learning', 'deep learning', 'deep learning']",[],[]
15,Optimization and Heuristics,Optimization technology is an important part of analytics.åÊ Optimization allows you to mathematically ÛÏnarrow your choices the very best when there are virtually innumerable feasible options and comparing them is difficult.Û,"['innumerable feasible options', 'Optimization technology', 'analytics.åÊ Optimization', 'choices', 'difficult.\x89Û\x9d']","['Mathematics', 'Optimization', 'Applied mathematics']",[],[],[]
16,Industry Practicum,"Concurrent with the coursework and under the guidance of business and technical advisers, students work in small teams to integrate coursework into an industry supplied project.","['technical advisers', 'coursework', 'small teams', 'guidance', 'business', 'students', 'industry', 'project']","['Small business', 'Project management']",[],[],[]
17,Predictive Models for Credit Risk Management,"This course introduces credit risk management for financial services industry. It focuses on how predictive models are developed and used for credit risk management throughout different stages of the credit life cycle (acquisition, authorization, accounts management, and recoveries). The objective is to prepare the students for future employment in financial services industry with the business knowledge and hands-on model development experience using simulated industry data sets.","['financial services industry', 'credit risk management', 'hands-on model development', 'simulated industry data', 'credit life cycle', 'predictive models', 'different stages', 'future employment', 'business knowledge', 'recoveries', 'authorization', 'objective', 'acquisition', 'course', 'students', 'experience']","['Financial services', 'Management', 'Insurance', 'Operational risk', 'Credit rating', 'Knowledge', 'Risk management', 'Risk', 'Credit risk', 'Interest', 'Liquidity risk', 'Bank', 'Credit reference', 'Market risk', 'Corporate finance', 'Education', 'Actuarial science', 'Model', 'Future']",[],[],[]
18,Healthcare Analytics,"Global healthcare problems are complex and require a multi-leveled multi-pronged approach inclusive of a diverse set of stakeholders. While the data used for model training and decision making is being aggregated rapidly, it presents its unique challenges such as errors, missingness and sparsity. Additionally, the models trained for healthcare problems often have unique aspects. This course introduces additional concepts in data analytics, based on tools and techniques from operations research and epidemiology embedded in information technology to address health analytics and decision problems.","['multi-leveled multi-pronged approach', 'Global healthcare problems', 'decision making', 'health analytics', 'diverse set', 'data analytics', 'decision problems', 'model training', 'unique challenges', 'additional concepts', 'operations research', 'information technology', 'unique aspects', 'sparsity', 'stakeholders', 'epidemiology', 'errors', 'missingness', 'course', 'models']","['Data analysis', 'Health', 'Mathematics', 'Public health', 'Cognition', 'Decision making', 'Model', 'Training', 'Health care', 'Information technology']",[],[],[]
19,Social Networks Analysis,"This course explores the use of social network analysis to understand the growing connectivity and complexity in the world around us on different scales-ranging from small groups to the World Wide Web. It examines how we create social, economic, and technological networks, and how these networks enable and constrain our attitudes and behavior.","['social network analysis', 'World Wide Web', 'small groups', 'technological networks', 'complexity', 'connectivity', 'attitudes', 'course', 'behavior']","['World Wide Web', 'Social network', 'Networks', 'Network theory', 'Sociology', 'Tim Berners-Lee', 'Complex network', 'Network science', 'Systems theory', 'Self-organization', 'World', 'Web 2.0', 'Computer network', 'Social network analysis software']",[],[],[]
20,Capstone Design,"In this culminating project, students draw on the breadth and depth of the curriculum to address an industry-supplied problem in small teams.","['industry-supplied problem', 'small teams', 'breadth', 'depth', 'project', 'students', 'curriculum']","['Breadth-first search', 'Education']",[],[],[]
21,Numerical Linear Algebra,"Solution of linear systems, accuracy, stability, LU, Cholesky, QR, least squares problems, singular value decomposition, eigenvalue computation, iterative methods, Krylov subspace, Lanczos and Arnoldi processes, conjugate gradient, GMRES, direct methods for sparse matrices. Prerequisites: CME 108, MATH 114, MATH 104.","['singular value decomposition', 'Krylov subspace', 'conjugate gradient', 'eigenvalue computation', 'sparse matrices', 'Arnoldi processes', 'iterative methods', 'squares problems', 'linear systems', 'direct methods', 'Cholesky', 'GMRES', 'QR', 'Lanczos', 'Prerequisites', 'accuracy', 'stability', 'CME']","['Numerical linear algebra', 'Iterative method', 'Krylov subspace', 'Arnoldi iteration', 'Linear least squares', 'Singular value decomposition', 'Linear algebra']",[],[],[]
22,Discrete Mathematics and Algorithms,"Topics: Basic Algebraic Graph Theory, Matroids and Minimum Spanning Trees, Submodularity and Maximum Flow, NP-Hardness, Approximation Algorithms, Randomized Algorithms, The Probabilistic Method, and Spectral Sparsification using Effective Resistances. Topics will be illustrated with applications from Distributed Computing, Machine Learning, and large-scale Optimization. Prerequisites: CS 261 is highly recommended, although not required.Same as: MS&E 316","['Minimum Spanning Trees', 'Basic Algebraic Graph', 'Randomized Algorithms', 'Approximation Algorithms', 'Effective Resistances', 'Probabilistic Method', 'Spectral Sparsification', 'Maximum Flow', 'large-scale Optimization', 'Distributed Computing', 'Machine Learning', 'Matroids', 'Prerequisites', 'CS']","['Algorithm', 'Computer science', 'Graph theory', 'Combinatorics', 'Maxima and minima', 'Mathematics', 'Optimization', 'Approximation algorithm', 'Machine learning']","['Algorithms', 'Algorithms', 'Machine Learning']",[],[]
23,Optimization,"Applications, theories, and algorithms for finite-dimensional linear and nonlinear optimization problems with continuous variables. Elements of convex analysis, first- and second-order optimality conditions, sensitivity and duality. Algorithms for unconstrained optimization, and linearly and nonlinearly constrained problems. Modern applications in communication, game theory, auction, and economics. Prerequisites: MATH 113, 115, or equivalent.Same as: MS&E 311","['second-order optimality conditions', 'nonlinearly constrained problems', 'nonlinear optimization problems', 'finite-dimensional linear', 'continuous variables', 'convex analysis', 'unconstrained optimization', 'game theory', 'Modern applications', 'algorithms', 'Prerequisites', 'duality', 'sensitivity', 'theories', 'Elements', 'MATH', 'equivalent.Same', 'MS&E', 'communication']","['Operations research', 'Derivative', 'Linear programming', 'Optimization', 'Mathematics', 'Applied mathematics', 'Science', 'Economics', 'Scientific method', 'Game theory', 'Mathematical optimization', 'Greek loanwords', 'Calculus', 'Social sciences', 'Function', 'Fundamental physics concepts', 'Falsifiability', 'Nonlinear system', 'Physics', 'Chess', 'Theorem', 'Combinatorial game theory', 'Algorithm', 'Chaos theory', 'Vector space', 'Experiment', 'Mathematical analysis', 'Matrix', 'Nonlinear programming', 'Polynomial', 'Polytope', 'Dual problem', 'Mathematical logic', 'Artificial intelligence', 'Linear algebra', 'Branch and bound', 'Simplex algorithm', 'Real number', 'Auction', 'Mathematical model']","['algorithms', 'Algorithms']",[],[]
24,Stochastic Methods in Engineering,"The basic limit theorems of probability theory and their application to maximum likelihood estimation. Basic Monte Carlo methods and importance sampling. Markov chains and processes, random walks, basic ergodic theory and its application to parameter estimation. Discrete time stochastic control and Bayesian filtering. Diffusion approximations, Brownian motion and an introduction to stochastic differential equations. Examples and problems from various applied areas. Prerequisites: exposure to probability and background in analysis.Same as: MATH 228, MS&E 324","['basic limit theorems', 'stochastic differential equations', 'time stochastic control', 'Monte Carlo methods', 'likelihood estimation', 'various applied areas', 'probability theory', 'Diffusion approximations', 'Markov chains', 'Brownian motion', 'importance sampling', 'random walks', 'Bayesian filtering']","['Probability', 'Maximum likelihood', 'Stochastic process', 'Probability theory', 'Mathematics', 'Differential equation', 'Estimation theory', 'Markov chain', 'Monte Carlo method', 'Signal processing', 'Chaos theory', 'Random walk', 'Stochastic processes', 'Normal distribution', 'Likelihood function']","['probability', 'probability']",[],[]
25,Randomized Algorithms and Probabilistic Analysis,"Randomness pervades the natural processes around us, from the formation of networks, to genetic recombination, to quantum physics. Randomness is also a powerful tool that can be leveraged to create algorithms and data structures which, in many cases, are more efficient and simpler than their deterministic counterparts. This course covers the key tools of probabilistic analysis, and application of these tools to understand the behaviors of random processes and algorithms. Emphasis is on theoretical foundations, though we will apply this theory broadly, discussing applications in machine learning and data analysis, networking, and systems. Topics include tail bounds, the probabilistic method, Markov chains, and martingales, with applications to analyzing random graphs, metric embeddings, random walks, and a host of powerful and elegant randomized algorithms. Prerequisites: CS 161 and STAT 116, or equivalents and instructor consent.Same as: CS 265","['deterministic counterparts', 'genetic recombination', 'metric embeddings', 'probabilistic analysis', 'random processes', 'random walks', 'random graphs', 'powerful tool', 'probabilistic method', 'natural processes', 'tail bounds', 'Markov chains', 'theoretical foundations', 'data structures', 'key tools', 'machine learning', 'instructor consent.Same', 'data analysis', 'algorithms', 'Randomness', 'CS', 'martingales', 'applications', 'Prerequisites', 'STAT', 'equivalents', 'behaviors', 'formation', 'networks', 'physics', 'cases', 'course', 'application', 'Emphasis', 'theory', 'networking']","['Determinism', 'Scientific method', 'Probability', 'Randomness', 'Chaos theory', 'Stochastic process', 'Quantum mechanics', 'Random variable', 'Markov chain', 'Free will', 'Physics', 'Complexity', 'Algorithm', 'Probability theory', 'Kinetic theory', 'Theory', 'Computer program', 'Pseudorandom number generator', 'Probabilistic method', 'Random walk', 'Cryptography']","['algorithms', 'algorithms', 'machine learning', 'algorithms']",[],[]
26,Introduction to Statistical Inference,"Modern statistical concepts and procedures derived from a mathematical framework. Statistical inference, decision theory; point and interval estimation, tests of hypotheses; Neyman-Pearson theory. Bayesian analysis; maximum likelihood, large sample theory. Prerequisite: 116. http://statweb.stanford.edu/~sabatti/Stat200/index.html.","['Modern statistical concepts', 'large sample theory', 'interval estimation', 'maximum likelihood', 'Statistical inference', 'Bayesian analysis', 'mathematical framework', 'decision theory', 'Neyman-Pearson theory', 'Prerequisite', 'hypotheses', 'procedures', 'point', 'tests']","['Statistical inference', 'Scientific method', 'Estimation theory', 'Bayesian inference', 'Probability', 'Decision theory', 'Likelihood function', 'Bayesian probability', 'Statistics', 'Loss function', 'Logic', 'Maximum likelihood', 'Statistical hypothesis testing', 'Prior probability', ""Bayes' theorem"", 'Mathematics', 'Applied mathematics', 'Bayesian statistics', 'Influence diagram', 'Confidence interval', 'Logic and statistics', 'Control theory', 'Admissible decision rule', 'Statistical theory', 'Mathematical analysis', 'Theorem', 'Game theory', 'Bayes factor', 'Experiment', 'Falsifiability', 'Estimation', 'Science', 'Information theory', 'Calculus']",[],[],[]
27,Introduction to Regression Models and Analysis of Variance,Modeling and interpretation of observational and experimental data using linear and nonlinear regression methods. Model building and selection methods. Multivariable analysis. Fixed and random effects models. Experimental design. Pre- or corequisite: 200.,"['nonlinear regression methods', 'random effects models', 'Multivariable analysis', 'experimental data', 'Model building', 'selection methods', 'Experimental design', 'interpretation']","['Statistics', 'Model', 'Regression analysis', 'Linear regression', 'Model building']","['Modeling', 'regression']",[],[]
28,Introduction to Statistical Modeling,"Review of univariate regression. Multiple regression. Geometry, subspaces, orthogonality, projections, normal equations, rank deficiency, estimable functions and Gauss-Markov theorem. Computation via QR decomposition, Gramm-Schmidt orthogonalization and the SVD. Interpreting coefficients, collinearity, graphical displays. Fits and the Hat matrix, leverage & influence, diagnostics, weighted least squares and resistance. Model selection, Cp/Aic and crossvalidation, stepwise, lasso. Basis expansions, splines. Multivariate normal distribution theory. ANOVA: Sources of measurements, fixed and random effects, randomization. Emphasis on problem sets involving substantive computations with data sets. Prerequisites: consent of instructor, 116, 200, applied statistics course, CS 106A, MATH 114. (NB: prior to 2016-17 the 305ABC series was numbered as 305, 306A and 306B).","['Multivariate normal distribution', 'univariate regression', 'Multiple regression', 'QR decomposition', 'normal equations', 'rank deficiency', 'substantive computations', 'Gauss-Markov theorem', 'Basis expansions', 'Hat matrix', 'estimable functions', 'graphical displays', 'Gramm-Schmidt orthogonalization', 'CS 106A', 'Model selection', 'problem sets', 'data sets', 'random effects', 'statistics course', '305ABC series', 'subspaces', 'SVD', 'stepwise', 'randomization', 'coefficients', 'Prerequisites', 'splines', 'leverage', 'consent', 'projections', 'NB', 'Fits', 'squares', 'diagnostics', 'resistance', 'measurements', 'Review', 'influence', 'Geometry', 'orthogonality', 'collinearity', 'Cp/Aic', 'crossvalidation', 'Emphasis']","['Regression analysis', 'Linear least squares', 'Normal distribution', 'Mathematics', 'Statistics', 'Multivariate normal distribution', 'Analysis of variance', 'Carl Friedrich Gauss', 'Singular value decomposition', 'Variance', 'Orthogonality', 'Charles Sanders Peirce', 'Characteristic function', 'Sum of normally distributed random variables', 'Orthogonal matrix', 'Normally distributed and uncorrelated does not imply independent', 'Polynomial', 'Applied mathematics', 'Errors and residuals in statistics', 'Least squares', 'QR decomposition', 'Probability theory', 'Statistical terminology', 'Linear algebra', 'Multivariate statistics', 'Triangular matrix', 'Standard deviation', 'Stepwise regression', 'Matrix', 'Probability distribution', 'Determinant', 'Continuous distributions', 'Probability density function', 'Chi-square distribution', 'Design of experiments', 'Leverage', 'Total least squares', 'Scientific method', 'Confidence interval', 'Statistical theory', 'Design matrix', 'Covariance matrix']","['regression', 'regression', 'statistics']",[],[]
29,Modern Applied Statistics: Learning,"Overview of supervised learning. Linear regression and related methods. Model selection, least angle regression and the lasso, stepwise methods. Classification. Linear discriminant analysis, logistic regression, and support vector machines (SVMs). Basis expansions, splines and regularization. Kernel methods. Generalized additive models. Kernel smoothing. Gaussian mixtures and the EM algorithm. Model assessment and selection: crossvalidation and the bootstrap. Pathwise coordinate descent. Sparse graphical models. Prerequisites: STATS 305, 306A,B or consent of instructor.","['Linear discriminant analysis', 'Linear regression', 'support vector machines', 'Sparse graphical models', 'angle regression', 'logistic regression', 'Kernel smoothing', 'supervised learning', 'stepwise methods', 'Gaussian mixtures', 'Kernel methods', 'Basis expansions', 'additive models', 'EM algorithm', 'related methods', 'Model selection', 'Model assessment', 'regularization', 'SVMs', 'lasso', 'Prerequisites', 'splines', 'bootstrap', 'consent', 'STATS']","['Machine learning', 'Kernel trick', 'Regression analysis', 'Support vector machine', 'Logistic regression', 'Stepwise regression', 'Linear discriminant analysis', 'Linear classifier', 'Vector space', 'Linear algebra', 'Classification algorithms', 'Supervised learning', 'Psychometrics', 'Statistics']","['supervised', 'Linear', 'regression', 'regression', 'Linear', 'regression']",[],[]
30,Modern Applied Statistics: Data Mining,"Two-part sequence. New techniques for predictive and descriptive learning using ideas that bridge gaps among statistics, computer science, and artificial intelligence. Emphasis is on statistical aspects of their application and integration with more standard statistical methodology. Predictive learning refers to estimating models from data with the goal of predicting future outcomes, in particular, regression and classification models. Descriptive learning is used to discover general patterns and relationships in data without a predictive goal, viewed from a statistical perspective as computer automated exploratory analysis of large complex data sets.","['descriptive learning', 'standard statistical methodology', 'large complex data', 'Two-part sequence', 'Predictive learning', 'predictive goal', 'exploratory analysis', 'New techniques', 'future outcomes', 'artificial intelligence', 'general patterns', 'statistical aspects', 'classification models', 'statistical perspective']","['Statistics', 'Scientific method', 'Mathematics', 'Computer', 'Regression analysis', 'Artificial intelligence', 'Machine learning', 'Computer science', 'Prediction', 'Forecasting', 'Alan Turing', 'Cognitive science', 'Future', 'Logic', 'Software engineering', 'Futurology', 'Data set', 'Computational science', 'Real analysis', 'Prediction interval', 'Computer program', 'Science fiction', 'Applied mathematics', 'Mathematical analysis', 'Carnegie Mellon University', 'Psychology', 'Computation', 'Game theory', 'Data', 'Pattern recognition', 'Calculus', 'Cybernetics', 'Knowledge', 'Philosophy of mind', 'Intelligence', 'Exploratory data analysis', 'Estimation', 'Formal sciences', 'Intelligent agent', 'Analysis of variance']","['statistics', 'regression']",[],[]
31,Advanced Software Development for Scientists and Engineers,"Advanced topics in software development, debugging, and performance optimization are covered. The capabilities and usage of common libraries and frameworks such as BLAS, LAPACK, FFT, PETSc, and MKL/ACML are reviewed. Computer representation of integer and floating point numbers, and interoperability between C/C++ and Fortran is described. More advanced software engineering topics including: representing data in files, signals, unit and regression testing, and build automation. The use of debugging tools including static analysis, gdb, and Valgrind are introduced. An introduction to computer architecture covering processors, memory hierarchy, storage, and networking provides a foundation for understanding software performance. Profiles generated using gprof and perf are used to help guide the performance optimization process. Computational problems from various science and engineering disciplines will be used in assignments. Prerequisites: CME 200 / ME 300A and CME 211.","['floating point numbers', 'performance optimization', 'advanced software engineering', 'performance optimization process', 'software development', 'Advanced topics', 'regression testing', 'common libraries', 'memory hierarchy', 'static analysis', 'software performance', 'Computational problems', 'various science', 'engineering disciplines', 'CME', 'debugging', 'PETSc', '300A', 'Valgrind', 'gprof', 'LAPACK', 'BLAS', 'FFT', 'gdb', 'Prerequisites', 'integer', 'frameworks', 'interoperability', 'C/C++', 'signals', 'assignments', 'usage', 'Fortran', 'capabilities', 'processors', 'MKL/ACML', 'representation', 'data', 'files', 'unit', 'automation', 'tools', 'introduction']","['Software testing', 'Floating point', 'Software engineering', 'Engineering', 'Unit testing', 'Numerical analysis', 'Computer', 'Computing', 'Fortran', 'Algorithm', 'Central processing unit', 'Computer program', 'Fixed-point arithmetic', 'Software architecture', 'Computer data storage', 'Assembly language', 'Rational number', 'Computational science', 'Software optimization', 'Computer science', 'Z3', 'Computer programming', 'FLOPS', 'IBM 704', 'Memory hierarchy', 'Processor register', 'Regression testing', 'Microprocessor', 'Programmer', 'Valgrind', 'Mathematics', 'C', 'Von Neumann architecture', 'Computational problem', 'Introduction', 'Artificial intelligence']",['regression'],[],['C/C++']
32,"Introduction to parallel computing using MPI, openMP, and CUDA","This class will give hands on experience with programming multicore processors, graphics processing units (GPU), and parallel computers. Focus will be on the message passing interface (MPI, parallel clusters) and the compute unified device architecture (CUDA, GPU). Topics will include: network topologies, modeling communication times, collective communication operations, parallel efficiency, MPI, dense linear algebra using MPI. Symmetric multiprocessing (SMP), pthreads, openMP. CUDA, combining MPI and CUDA, dense linear algebra using CUDA, sort, reduce and scan using CUDA. Pre-requisites include: C programming language and numerical algorithms (solution of differential equations, linear algebra, Fourier transforms).Same as: ME 339","['dense linear algebra', 'programming multicore processors', 'graphics processing units', 'compute unified device', 'collective communication operations', 'modeling communication times', 'MPI', 'parallel computers', 'parallel clusters', 'parallel efficiency', 'network topologies', 'differential equations', 'numerical algorithms', 'GPU', 'Pre-requisites', 'pthreads', 'openMP', 'Fourier', 'hands', 'sort', 'class', 'experience', 'Focus', 'message', 'interface']","['Parallel computing', 'Programming language', 'Message Passing Interface', 'Mathematics', 'Algorithm', 'Supercomputer', 'OpenMP', 'Graphics processing unit', 'CUDA', 'C', 'Java', 'Fortran', 'C++', 'Computer', 'Computer program', 'POSIX Threads', 'Symmetric multiprocessing', 'Geometry', 'Real number', 'Vector space', 'Numerical analysis', 'Stream processing', 'GPGPU', 'Differential equation', 'Computer programming', ""Gustafson's law"", 'Speedup', 'Elementary algebra', 'Computer science', 'Subroutine']","['programming', 'programming', 'algorithms']",[],['C']
33,Distributed Algorithms and Optimization,"The emergence of clusters of commodity machines with parallel processing units has brought with it a slew of new algorithms and tools. Many fields such as Machine Learning and Optimization have adapted their algorithms to handle such clusters. Topics include distributed and parallel algorithms for: Optimization, Numerical Linear Algebra, Machine Learning, Graph analysis, Streaming algorithms, and other problems that are challenging to scale on a commodity cluster. The class will focus on analyzing parallel and distributed programs, with some implementation using Apache Spark and TensorFlow.","['parallel processing units', 'Numerical Linear Algebra', 'parallel algorithms', 'new algorithms', 'Machine Learning', 'commodity machines', 'commodity cluster', 'Apache Spark', 'Graph analysis', 'clusters', 'slew', 'emergence', 'Optimization', 'tools', 'fields', 'Topics', 'class', 'programs', 'problems']","['Algorithm', 'Parallel computing', 'Mathematics', 'Numerical analysis', 'Machine learning', 'Matrix', 'Parallel algorithm', 'Linear algebra', 'Real number', 'Vector space', 'Machines', 'Algorithmic efficiency', 'Linear programming', 'Discrete mathematics', 'Simplex algorithm', 'Derivative', 'Greek loanwords', 'Scientific method', 'Distributed algorithms', 'Computer program', 'Machine', 'Analysis']","['algorithms', 'Machine Learning', 'algorithms', 'algorithms', 'Linear Algebra', 'Machine Learning', 'algorithms']",[],['Spark']
34,Parallel Methods in Numerical Analysis,"Emphasis is on techniques for obtaining maximum parallelism in numerical algorithms, especially those occurring when solving matrix problems, partial differential equations, and the subsequent mapping onto the computer. Implementation issues on parallel computers. Topics: parallel architecture, programming models (MPI, GPU Computing with CUDA åÀ quick review), matrix computations, FFT, fast multiple methods, domain decomposition, graph partitioning, discrete algorithms. Prerequisites: 302 or 200 (ME 300A), 213 or equivalent, or consent of instructor. Recommended: differential equations and knowledge of a high-level programming language such as C or C++ (F90/95 also allowable).","['partial differential equations', 'åÀ quick review', 'high-level programming language', 'fast multiple methods', 'maximum parallelism', 'numerical algorithms', 'matrix problems', 'matrix computations', 'subsequent mapping', 'GPU Computing', 'parallel computers', 'discrete algorithms', 'graph partitioning', 'parallel architecture', 'Implementation issues', 'programming models', '300A', 'CUDA', 'Prerequisites', 'FFT', 'decomposition', 'MPI', 'consent']","['Algorithm', 'Computer', 'Computer science', 'Programming language', 'Parallel computing', 'Derivative', 'Graphics processing unit', 'CUDA', 'Parallel algorithm', 'Numerical analysis', 'Mathematics', 'Differential equation', 'Partial differential equation', 'Computer program', 'Computing', 'Computer programming']","['algorithms', 'programming', 'algorithms', 'programming']",[],"['C', 'C++']"
35,Parallel Computing,"This course is an introduction to parallelism and parallel programming. Most new computer architectures are parallel; programming these machines requires knowledge of the basic issues of and techniques for writing parallel software. Topics: varieties of parallelism in current hardware (e.g., fast networks, multicore, accelerators such as GPUs, vector instruction sets), importance of locality, implicit vs. explicit parallelism, shared vs. non-shared memory, synchronization mechanisms (locking, atomicity, transactions, barriers), and parallel programming models (threads, data parallel/streaming, MapReduce, Apache Spark, SPMD, message passing, SIMT, transactions, and nested parallelism). Significant parallel programming assignments will be given as homework. The course is open to students who have completed the introductory CS course sequence through 110 and have taken CS 143.","['parallel programming', 'parallel programming models', 'parallel programming assignments', 'CS course sequence', 'explicit parallelism', 'parallel software', 'new computer architectures', 'synchronization mechanisms', 'Apache Spark', 'basic issues', 'vector instruction', 'message passing', 'fast networks', 'non-shared memory', 'atomicity', 'SPMD', 'GPUs', 'multicore', 'accelerators', 'transactions', 'locality', 'homework', 'barriers', 'introduction', 'importance', 'varieties', 'threads', 'machines', 'knowledge', 'techniques', 'Topics', 'data']","['Parallel computing', 'Central processing unit', 'Parallel programming model', 'Message Passing Interface', 'Instruction set', 'Barrier', 'Computer']","['programming', 'programming', 'programming', 'programming']",[],"['MapReduce', 'Spark']"
36,Parallel Computer Architecture and Programming,"The principles and tradeoffs in the design of parallel architectures. Emphasis is on naming, latency, bandwidth, and synchronization in parallel machines. Case studies on shared memory, message passing, data flow, and data parallel machines illustrate techniques. Architectural studies and lectures on techniques for programming parallel computers. Programming assignments on one or more commercial multiprocessors. Prerequisites: EE 282, and reasonable programming experience.","['parallel machines', 'data parallel machines', 'programming parallel computers', 'parallel architectures', 'reasonable programming experience', 'commercial multiprocessors', 'message passing', 'Case studies', 'data flow', 'Architectural studies', 'tradeoffs', 'latency', 'Prerequisites', 'EE', 'synchronization', 'bandwidth', 'techniques', 'assignments', 'principles', 'design', 'Emphasis']","['Parallel computing', 'Computer', 'Algorithm', 'Inter-process communication', 'Greek loanwords']","['programming', 'Programming', 'programming']",[],[]
37,Advanced Multi-Core Systems,"In-depth coverage of the architectural techniques used in modern, multi-core chips for mobile and server systems. Advanced processor design techniques (superscalar cores, VLIW cores, multi-threaded cores, energy-efficient cores), cache coherence, memory consistency, vector processors, graphics processors, heterogeneous processors, and hardware support for security and parallel programming. Students will become familiar with complex trade-offs between performance-power-complexity and hardware-software interactions. A central part of CS316 is a project on an open research question on multi-core technologies. Prerequisites: EE 180 (formerly 108B) and EE 282. Recommended: CS 149.","['superscalar cores', 'VLIW cores', 'energy-efficient cores', 'multi-threaded cores', 'Advanced processor design', 'multi-core chips', 'open research question', 'heterogeneous processors', 'vector processors', 'multi-core technologies', 'graphics processors', 'cache coherence', 'hardware-software interactions', 'complex trade-offs', 'In-depth coverage', 'memory consistency', 'server systems', 'architectural techniques', 'parallel programming', 'hardware support', 'EE', 'Prerequisites']","['Parallel computing', 'Central processing unit', 'Vector processor', 'SIMD', 'Superscalar', 'Instruction set', 'ILLIAC IV', 'Stream processing', 'Research', 'Consistency model', 'CPU cache', 'Multi-core processor', 'Simultaneous multithreading', 'Computer architecture', 'X86', 'Computer', 'Instruction level parallelism', 'Computer program', 'Personal computer', 'Graphics processing unit', 'Supercomputer', 'Scalar processor', 'Graphic design', 'CUDA', 'Cray-1']",['programming'],[],[]
38,Representations and Algorithms for Computational Molecular Biology,"Topics: introduction to bioinformatics and computational biology, algorithms for alignment of biological sequences and structures, computing with strings, phylogenetic tree construction, hidden Markov models, basic structural computations on proteins, protein structure prediction, protein threading techniques, homology modeling, molecular dynamics and energy minimization, statistical analysis of 3D biological data, integration of data sources, knowledge representation and controlled terminologies for molecular biology, microarray analysis, machine learning (clustering and classification), and natural language text processing. Prerequisite: CS 106B; recommended: CS161; consent of instructor for 3 units.Same as: BIOMEDIN 214, CS 274, GENE 214","['protein threading techniques', 'protein structure prediction', 'phylogenetic tree construction', 'basic structural computations', '3D biological data', 'natural language text', 'CS 106B', 'homology modeling', 'Markov models', 'energy minimization', 'biological sequences', 'microarray analysis', 'computational biology', 'molecular dynamics', 'statistical analysis', 'knowledge representation', 'data sources', 'molecular biology', 'terminologies', 'Prerequisite', 'consent', 'alignment', 'strings', 'proteins', 'bioinformatics', 'algorithms', 'Topics', 'introduction', 'structures', 'integration', 'machine', 'classification']","['Bioinformatics', 'Protein', 'DNA', 'Molecular biology', 'Protein structure prediction', 'Protein structure', 'Biology', 'Evolution', 'Sequence alignment', 'Gene', 'Phylogenetics', 'Homology modeling', 'Computer science', 'Machine learning', 'Phylogenetic tree', 'Computational biology', 'Species', 'Hidden Markov model', 'Structural genomics', 'Computational genomics', 'Scientific method', 'Cell biology', 'Protein methods', 'Biostatistics', 'Computer', 'Life', 'Drug design', 'Data', 'Genetics', 'Genetic algorithm', 'Proteome', 'Organism', 'Molecular dynamics', 'Secondary structure', 'DNA sequencing theory', 'Protein folding', 'Cladistics', 'Tertiary structure', 'Primary structure', 'Biophysics', 'Amino acid', 'Structure', 'Multiple sequence alignment', 'Computational phylogenetics', 'DNA microarray', 'Computing', 'Biochemistry', 'Formal sciences', 'RNA', 'Threading']","['algorithms', 'machine learning', 'clustering']",[],[]
39,Data Driven Medicine,"The widespread adoption of electronic health records (EHRs) has created a new source of åÀbig dataåÀåÀnamely, the record of routine clinical practiceåÀas a by-product of care. This graduate class will teach you how to use EHRs and other patient data to discover new clinical knowledge and improve healthcare. Upon completing this course, you should be able to: differentiate between and give examples of categories of research questions and the study designs used to address them, describe common healthcare data sources and their relative advantages and limitations, extract and transform various kinds of clinical data to create analysis-ready datasets, design and execute an analysis of a clinical dataset based on your familiarity with the workings, applicability, and limitations of common statistical methods, evaluate and criticize published research using your knowledge of 1-4 to generate new research ideas and separate hype from reality. Prerequisites: CS 106A or equivalent, STATS 60 or equivalent. Recommended: STATS 216, CS 145, STATS 305.","['electronic health records', 'transform various kinds', 'new clinical knowledge', 'healthcare data sources', 'common statistical methods', 'new research ideas', 'widespread adoption', 'new source', 'CS 106A', 'relative advantages', 'graduate class', 'clinical dataset', 'analysis-ready datasets', 'separate hype', 'patient data', 'study designs', 'research questions', 'clinical data', 'EHRs', 'STATS', 'limitations', 'by-product', 'criticize', 'familiarity', 'Prerequisites', 'applicability', 'workings', 'extract', 'evaluate', 'åÀbig', 'course']","['Statistics', 'Data', 'Data set', 'Scientific method', 'Electronic health record', 'Health care', 'Epidemiology', 'Source code', 'Applied mathematics', 'Biostatistics', 'Analysis of variance', 'Social research']",[],[],[]
40,Modern Statistics for Modern Biology,"Application based course in nonparametric statistics. Modern toolbox of visualization and statistical methods for the analysis of data, examples drawn from immunology, microbiology, cancer research and ecology. Methods covered include multivariate methods (PCA and extensions), sparse representations (trees, networks, contingency tables) as well as nonparametric testing (Bootstrap, permutation and Monte Carlo methods). Hands on, use R and cover many Bioconductor packages. Prerequisite: Minimal familiarity with computers. Instructor consent. Cross-listed as STATS 366.Same as: STATS 366","['Monte Carlo methods', 'nonparametric statistics', 'nonparametric testing', 'sparse representations', 'Bioconductor packages', 'Minimal familiarity', 'Modern toolbox', 'contingency tables', 'multivariate methods', 'Instructor consent', 'cancer research', 'statistical methods', 'STATS', 'Prerequisite', 'permutation', 'Bootstrap', 'PCA', 'immunology', 'microbiology']","['Statistics', 'Resampling']","['statistics', 'visualization']",[],['R']
41,Social and Information Network Analysis,"Networks are a fundamental tool for modeling complex social, technological, and biological systems. Coupled with emergence of online social networks and large-scale data availability in biological sciences, this course focuses on the analysis of massive networks which provide many computational, algorithmic, and modeling challenges. This course develops computational tools that reveal how the social, technological, and natural worlds are connected, and how the study of networks sheds light on these connections. nTopics include: how information spreads through society; robustness and fragility of food webs and financial markets; algorithms for the World Wide Web; friend prediction in online social networks; identification of functional modules in biological networks; disease outbreak detection.","['online social networks', 'large-scale data availability', 'disease outbreak detection', 'World Wide Web', 'fundamental tool', 'modeling complex', 'massive networks', 'biological systems', 'food webs', 'networks sheds', 'friend prediction', 'modeling challenges', 'natural worlds', 'biological sciences', 'financial markets', 'computational tools', 'functional modules', 'biological networks', 'fragility', 'robustness']","['World Wide Web', 'Sociology', 'Epidemiology', 'Web 2.0', 'Ecology', 'Science', 'World', 'Natural selection', 'Algorithm', 'Systems theory', 'Species', 'Natural science', 'Computer science', 'Discrete mathematics', 'Programming language', 'Algorithmic efficiency', 'Complex system', 'Computational complexity theory', 'Life', 'Al-Jahiz', 'Computational geometry', 'Society', 'Phylogenetics', 'Charles Darwin', 'Natural environment', 'Tim Berners-Lee', 'Biology', 'Tool', 'Paleontology', 'Computer', 'Internet', 'Outbreak', 'Analysis of algorithms', 'Complexity', 'Entomology', 'Aristotle', 'Self-organization', 'Computer program', 'Scientific method']",['algorithms'],[],[]
42,Machine Learning,"Topics: statistical pattern recognition, linear and non-linear regression, non-parametric methods, exponential family, GLMs, support vector machines, kernel methods, model/feature selection, learning theory, VC dimension, clustering, density estimation, EM, dimensionality reduction, ICA, PCA, reinforcement learning and adaptive control, Markov decision processes, approximate dynamic programming, and policy search. Prerequisites: linear algebra, and basic probability and statistics.Same as: STATS 229","['statistical pattern recognition', 'support vector machines', 'approximate dynamic programming', 'dimensionality reduction', 'non-linear regression', 'non-parametric methods', 'VC dimension', 'density estimation', 'exponential family', 'Markov decision', 'linear algebra', 'kernel methods', 'adaptive control', 'reinforcement learning', 'model/feature selection', 'basic probability', 'policy search', 'GLMs', 'Prerequisites', 'PCA', 'clustering', 'STATS', 'Topics', 'theory']","['Machine learning', 'Vector space', 'Mathematics', 'Statistics', 'Dimension', 'Linear algebra', 'Markov decision process', 'Probability', 'Pattern recognition', 'Kernel density estimation', 'Real number', 'Regression analysis', 'Non-parametric statistics', 'Support vector machine', 'Algebra', 'Statistical classification', 'Histogram', 'Estimation', 'Resampling']","['regression', 'clustering', 'programming', 'probability', 'statistics']",[],[]
43,Convolutional Neural Networks for Visual Recognition,"Computer Vision has become ubiquitous in our society, with applications innsearch, image understanding, apps, mapping, medicine, drones, andnself-driving cars. Core to many of these applications are the tasks of image classification, localization and detection. This course is a deep dive into details of neural network architectures with a focus on learning end-to-end models for these tasks, particularly image classification. During the 10-week course, students will learn to implement, train and debug their own neural networks and gain a detailed understanding of cutting-edge research in computer vision. The final assignment will involve training a multi-million parameter convolutional neural network and applying it on the largest image classification dataset (ImageNet). We will focus on teaching how to set up the problem of image recognition, the learning algorithms (e.g. backpropagation), practical engineering tricks for training and fine-tuning the networks and guide the students through hands-on assignments and a final course project. Much of the background and materials of this course will be drawn from the ImageNet Challenge: http://image-net.org/challenges/LSVRC/2014/index. Prerequisites: Proficiency in Python; familiarity with C/C++; CS 131 and CS 229 or equivalents; Math 21 or equivalent, linear algebra.","['image classification', 'neural network architectures', 'convolutional neural network', 'image classification dataset', 'practical engineering tricks', 'final course project', 'multi-million parameter', 'neural networks', '10-week course', 'andnself-driving cars', 'image understanding', 'applications innsearch', 'end-to-end models', 'e.g. backpropagation', 'cutting-edge research', 'deep dive', 'final assignment', 'hands-on assignments', 'image recognition', 'linear algebra', 'ImageNet Challenge', 'tasks', 'CS', 'vision', 'students', 'drones', 'apps', 'Prerequisites', 'familiarity', 'equivalents', 'Proficiency', 'localization', 'society', 'mapping', 'medicine', 'C/C++', 'Core', 'detection', 'details', 'teaching', 'problem', 'Math', 'background', 'materials', 'http://image-net.org/challenges/LSVRC/2014/index']","['Artificial intelligence', 'Neural network', 'Machine learning', 'Artificial neural network', 'Neuroscience', 'Mathematics', 'Education', 'Learning', 'Cognitive science', 'Algorithm', 'Artificial neuron', 'Perceptron', 'Unsupervised learning', 'Networks', 'Neural networks', 'Statistical classification', 'Logistic function', 'Predictive analytics', 'C', 'Network architecture', 'English-language films', 'Skill', 'The Final', 'Deep diving', 'Mathematical model', 'Engineering', 'Linear algebra', 'Ubiquitous computing', 'Computer network', 'Psychology', 'Knowledge', 'Optical character recognition', 'Problem of evil', 'Ambient music']",['algorithms'],[],"['Python', 'C/C++']"
44,Mining Massive Data Sets,"Availability of massive datasets is revolutionizing science and industry. This course discusses data mining and machine learning algorithms for analyzing very large amounts of data. The focus is on algorithms and systems for mining big data. nTopics include: Big data systems (Hadoop, Spark, Hive); Link Analysis (PageRank, spam detection, hubs-and-authorities); Similarity search (locality-sensitive hashing, shingling, minhashing, random hyperplanes); Stream data processing; Analysis of social-network graphs; Association rules; Dimensionality reduction (UV, SVD, and CUR decompositions); Algorithms for very-large-scale mining (clustering, nearest-neighbor search); Large-scale machine learning (gradient descent, support-vector machines, classification, and regression); Submodular function optimization; Computational advertising. Prerequisites: At least one of CS107 or CS145.","['Big data systems', 'Stream data processing', 'Submodular function optimization', 'massive datasets', 'CUR decompositions', 'large amounts', 'data mining', 'gradient descent', 'social-network graphs', 'spam detection', 'random hyperplanes', 'Large-scale machine', 'Association rules', 'nearest-neighbor search', 'support-vector machines', 'Computational advertising', 'algorithms', 'Hadoop', 'shingling', 'SVD', 'Prerequisites', 'Similarity', 'Hive', 'PageRank', 'Spark', 'Analysis', 'regression', 'Availability', 'science', 'industry', 'course', 'focus', 'nTopics', 'hubs-and-authorities']","['Machine learning', 'Artificial intelligence', 'Singular value decomposition']","['machine learning', 'algorithms', 'machine learning', 'gradient', 'descent', 'regression', 'algorithms', 'big data', 'Big data', 'Algorithms', 'clustering']",[],"['Hadoop', 'Spark', 'Hive']"
45,Topics in Computer Graphics,"Topic changes each quarter. Recent topics: computational photography, datannvisualization, character animation, virtual worlds, graphics architectures, advanced rendering. See http://graphics.stanford.edu/courses for offererings and prerequisites. May be repeated for credit.","['Topic changes', 'graphics architectures', 'virtual worlds', 'Recent topics', 'computational photography', 'character animation', 'prerequisites', 'rendering', 'quarter']","['3D computer graphics', 'Digital photography']",[],[],[]
46,Geostatistics,"Overview of some of the most important data science methods (statistics, machine learning & computer vision) relevant for geological sciences, as well as other fields in the Earth Sciences. Areas covered are: extreme value statistics for predicting rare events; compositional data analysis for geochemistry; multivariate analysis for designing data & computer experiments; probabilistic aggregation of evidence for spatial mapping; functional data analysis for multivariate environmental datasets, spatial regression and modeling spatial uncertainty with covariate information (geostatistics). Identification & learning of geo-objects with computer vision. Focus on practicality rather than theory. Matlab exercises on realistic data problems.Same as: GS 240","['modeling spatial uncertainty', 'multivariate environmental datasets', 'important data science', 'compositional data analysis', 'extreme value statistics', 'functional data analysis', 'realistic data problems.Same', 'spatial regression', 'spatial mapping', 'multivariate analysis', 'probabilistic aggregation', 'geological sciences', 'Earth Sciences', 'rare events', 'practicality', 'vision']","['Scientific method', 'Geography', 'Statistics', 'Geology', 'Theory', 'Science', 'Physics', 'Earth', 'Experiment', 'Paleontology', 'Mathematics', 'Extreme value theory', 'Machine learning', 'Chemistry', 'Data', 'Data analysis', 'Regression analysis', 'Artificial intelligence', 'Multivariate statistics', 'Calculus', 'Biogeochemistry', 'Earth science', 'Kriging', 'Knowledge', 'Optimization', 'Geometallurgy', 'Data set', 'Theophrastus']","['statistics', 'machine learning', 'statistics', 'regression']",[],['Matlab']
47,Business Intelligence from Big Data,"The objective of this course is to analyze real-world situations where significant competitive advantage can be obtained through large-scale data analysis, with special attention to what can be done with the data and where the potential pitfalls lie. Students will be challenged to develop business-relevant questions and then solve for them by manipulating large data sets. Problems from advertising, eCommerce, finance, healthcare, marketing, and revenue management are presented. Students learn to apply software (such as R and SQL) to data sets to create knowledge that will inform decisions. The course covers fundamentals of statistical modeling, machine learning, and data-driven decision making. Students are expected to layer these topics over an existing facility with mathematical notation, algebra, calculus, probability, and basic statistics.","['large-scale data analysis', 'data-driven decision making', 'large data sets', 'real-world situations', 'potential pitfalls', 'special attention', 'revenue management', 'business-relevant questions', 'mathematical notation', 'basic statistics', 'statistical modeling', 'machine learning', 'Students', 'course']","['Statistics', 'Mathematics', 'Learning', 'Scientific method', 'Decision making', 'Data', 'Risk', 'Geometry', 'Decision theory', 'Knowledge', 'Probability theory', 'Marketing', 'Education', 'SQL', 'Neuropsychological assessment', 'Applied mathematics', 'Data set', 'Machine learning', 'Probability', 'Unsolved problems in neuroscience', 'Psychology', 'Decision making software', 'Real number', 'Problem solving', 'Data visualization', 'Indian mathematics', 'Comparison of relational database management systems']","['machine learning', 'probability', 'statistics']",[],"['R', 'SQL']"
48,Human Neuroimaging Methods,"This course introduces the student to human neuroimaging using magnetic resonance scanners. The course is a mixture of lectures and hands-on software tutorials. The course begins by introducing basic MR principles. Then various MR measurement modalities are described, including several types of structural and functional imaging methods. Finally algorithms for analyzing and visualizing the various types of neuroimaging data are explained, including anatomical images, functional data, diffusion imaging (e.g., DTI) and magnetization transfer. Emphasis is on explaining software methods used for interpreting these types of data.","['magnetic resonance scanners', 'MR measurement modalities', 'basic MR principles', 'hands-on software tutorials', 'functional imaging methods', 'human neuroimaging', 'neuroimaging data', 'magnetization transfer', 'anatomical images', 'diffusion imaging', 'software methods', 'various types', 'functional data']","['Medical imaging', 'Magnetic resonance imaging', 'Scientific method', 'Magnetic moment', 'Critical thinking', 'Radiology', 'Computer program', 'Debut albums']",['algorithms'],[],[]
49,Paradigms for Computing with Data,"Programming and computing techniques for the requirements of data science: acquisition and organization of data; visualization, modelling and inference for scientific applications; presentation and interactive communication of results. Emphasis on computing for substantial projects. Software development with emphasis on R, plus other key software tools. Prerequisites: Programming experience including familiarity with R; computing at least at the level of CS 106; statistics at the level of STATS 110 or 141.","['key software tools', 'substantial projects', 'scientific applications', 'interactive communication', 'data science', 'computing techniques', 'Software development', 'Prerequisites', 'familiarity', 'inference', 'CS', 'STATS', 'visualization', 'emphasis', 'modelling', 'acquisition', 'level', 'requirements', 'organization', 'presentation', 'results', 'experience']","['Computer program', 'Computer', 'Mathematics', 'Statistics', 'Software engineering', 'Scientific method', 'Sociology', 'System software', 'Experiment', 'Data', 'Pseudoscience', 'Computational science', 'Human', 'Science', 'Computer science', 'Knowledge', 'Computer software', 'Interactivity', 'Project management', 'Application software', 'Empirical']","['Programming', 'visualization', 'Programming', 'statistics']",[],"['R', 'R']"
50,Programming for Data Science,"Overview of data structures, iteration, flow control, and program design relevant to data exploration and analysis. When and how to exploit pre-existing libraries.","['pre-existing libraries', 'flow control', 'program design', 'data structures', 'data exploration', 'iteration', 'Overview', 'analysis']",['Control flow'],[],[],[]
51,Computing Platforms for Data Science,"How to install, maintain, and use the data scientific software ÛÏstackÛ. The Unix operating system, integrated development environments, and problem solving strategies.","['data scientific software', 'integrated development environments', '\x89ÛÏstack\x89Û\x9d', 'Unix', 'problem', 'strategies']","['Problem solving', 'Microsoft', 'Sun Microsystems', 'Computer', 'Integrated development environment']",[],[],[]
52,Communication and Argumentation,"Effective oral and written communication, across diverse target audiences, to facilitate understanding and decision-making. How to present and interpret data, with productive skepticism and an awareness of assumptions and bias.","['diverse target audiences', 'productive skepticism', 'decision-making', 'assumptions', 'bias', 'understanding', 'data', 'awareness']","['Communication', 'Writing', 'Nonverbal communication', 'Critical thinking', 'Linguistics', 'Understanding', 'Awareness', 'Writing system']",[],[],[]
53,Descriptive Statistics and Probability for Data Science,Fundamental concepts in probability. Describing data generated from a probability distribution. Statistical view of data coming from a probability distribution.,"['probability distribution', 'Fundamental concepts', 'Statistical view', 'Describing data']","['Random variable', 'Statistics']","['probability', 'probability', 'probability']",[],[]
54,Data Wrangling,"Converting data from the form in which it is collected to the form needed for analysis. How to clean, filter, arrange, aggregate, and transform diverse data types, e.g. strings, numbers, and date-times.","['diverse data types', 'e.g. strings', 'arrange', 'aggregate', 'filter', 'form', 'analysis', 'numbers', 'date-times']",['Type system'],[],[],[]
55,Data Visualization I,"The design and implementation of static figures across all phases of data analysis, from ingest and cleaning to description and inference. Plotting tools in R and Python.","['static figures', 'data analysis', 'inference', 'phases', 'Python', 'design', 'implementation', 'description', 'tools']","['Design', 'Data']",[],[],"['R', 'Python']"
56,Algorithms and Data Structures,"How to choose and use appropriate algorithms and data structures to help solve data science problems. Key concepts such as recursion and algorithmic complexity (e.g., efficiency, scalability).","['data science problems', 'appropriate algorithms', 'Key concepts', 'data structures', 'recursion', 'scalability', 'efficiency']","['Algorithmic efficiency', 'Computational complexity theory', 'Computer science', 'Problem solving', 'Algorithm', 'Theory of computation', 'Analysis of algorithms', 'Computer', 'Divide and conquer algorithm', 'Randomized algorithm', 'Computer program', 'Cryptography', 'Kolmogorov complexity']",['algorithms'],[],[]
57,Statistical Inference and Computation I,"The statistical and probabilistic foundations of inference, developed jointly through mathematical derivations and simulation techniques. Important distributions and large sample results. The frequentist paradigm.","['probabilistic foundations', 'large sample results', 'mathematical derivations', 'frequentist paradigm', 'Important distributions', 'simulation techniques', 'inference']","['Applied mathematics', 'Statistics', 'Probability theory', 'Simulation', 'Mathematics']",['simulation'],[],[]
58,Regression I,"Linear models for a quantitative response variable, with multiple categorical and/or quantitative predictors. Matrix formulation of linear regression. Model assessment and prediction.","['quantitative response variable', 'quantitative predictors', 'linear regression', 'Linear models', 'Matrix formulation', 'Model assessment', 'prediction']","['Regression analysis', 'Forecasting', 'Linear regression', 'Econometrics', 'Prediction', 'Multivariate adaptive regression splines', 'Ordinary least squares', 'Errors and residuals in statistics', 'Censored regression model', 'Segmented regression', 'Model', 'Model theory', 'Generalized linear model']","['Linear', 'regression']",[],[]
59,Data Science Workflows,"Interactive vs. scripted/unattended analyses and how to move fluidly between them. Reproducibility through automation and dynamic, literate documents. The use of version control and file organization to enhance machine- and human-readability.","['literate documents', 'version control', 'file organization', 'Reproducibility', 'analyses', 'automation', 'human-readability']","['Scientific method', 'Document', 'Greek loanwords', 'Control system']",[],[],[]
60,Supervised Learning I,"Introduction to supervised machine learning, with a focus on classification. K-NN, Decision trees, SVM, how to combine models via ensembling: boosting, bagging, random forests. Basic machine learning concepts such as generalization error and overfitting.","['generalization error', 'supervised machine', 'random forests', 'Decision trees', 'Basic machine', 'SVM', 'Introduction', 'focus', 'classification', 'K-NN', 'models', 'concepts']","['Machine learning', 'Supervised learning', 'Statistical classification', 'Decision trees', 'Decision tree', 'Classification algorithms', 'Learning']","['supervised', 'machine learning', 'SVM', 'machine learning']",[],[]
61,Databases and Data Retrieval,"How to work with data stored in relational database systems or in formats utilizing markup languages. Storage structures and schemas, data relationships, and ways to query and aggregate such data.","['relational database systems', 'markup languages', 'Storage structures', 'data relationships', 'schemas', 'formats', 'ways']","['Relational database management system', 'Database', 'Relational database', 'SQL', 'Relational algebra', 'Relational model', 'Databases', 'Relation', 'Database model', 'Entity-relationship model', 'Database theory', 'Data modeling']",['database'],[],[]
62,Regression II,"Useful extensions to basic regression, e.g., generalized linear models, mixed effects, smoothing, robust regression, and techniques for dealing with missing data.","['generalized linear models', 'robust regression', 'basic regression', 'Useful extensions', 'mixed effects', 'smoothing', 'e.g.', 'techniques', 'data']","['Regression analysis', 'Linear regression', 'Statistics', 'Econometrics', 'Data analysis', 'Generalized linear model', 'Robust statistics']","['regression', 'regression']",[],[]
63,Feature and Model Selection ,"How to evaluate and select features and models. Cross-validation, ROC curves, feature engineering, the role of regularization. Automating these tasks with hyperparameter optimization.","['ROC curves', 'hyperparameter optimization', 'Cross-validation', 'regularization', 'tasks', 'features', 'models', 'engineering', 'role']",[],[],[],[]
64,Unsupervised Learning,"How to find groups and other structure in unlabeled, possibly high dimensional data. Dimension reduction for visualization and data analysis. Clustering, association rules, model fitting via the EM algorithm.","['high dimensional data', 'Dimension reduction', 'EM algorithm', 'model fitting', 'association rules', 'data analysis', 'visualization', 'groups', 'structure']","['Dimension', 'Abstract algebra', 'Data analysis', 'Data mining', 'Manifold', 'Euclidean space', 'Machine learning', 'Scientific method', 'Model theory']","['visualization', 'Clustering']",[],[]
65,Collaborative Software Development,"How to exploit practices from collaborative software development techniques in data scientific workflows. Appropriate use of abstraction and classes, the software life cycle, unit testing / continuous integration, and packaging for use by others.","['data scientific workflows', 'collaborative software development', 'software life cycle', 'continuous integration', 'unit testing', 'abstraction', 'practices', 'techniques', 'classes']","['Mathematics', 'Software engineering', 'System software', 'Extreme Programming', 'Build automation', 'Computer program', 'Test-driven development', 'Computer programming', 'Software testing', 'Calculus', 'Computer', 'Religion']",[],[],[]
66,"Privacy, Ethics, and Security","The legal, ethical, and security issues concerning data, including aggregated data. Proactive compliance with rules and, in their absence, principles for the responsible management of sensitive data. Case studies.","['Proactive compliance', 'security issues', 'Case studies', 'sensitive data', 'responsible management', 'absence', 'rules', 'principles']",['Case study'],[],['Proactive'],[]
67,Supervised Learning II,Stochastic gradient descent. Logistic Regression. Neural networks and deep learning: state-of-the-art implementation considerations in both software and hardware (GPUs).,"['Stochastic gradient descent', 'state-of-the-art implementation considerations', 'Logistic Regression', 'Neural networks', 'deep learning', 'GPUs', 'software', 'hardware']","['Gradient descent', 'Logistic function', 'Neural network', 'Logistic regression', 'Regression analysis', 'Stochastic gradient descent', 'Artificial neural network', 'Logit']","['gradient descent', 'Logistic Regression', 'deep learning']",[],[]
68,Web and Cloud Computing,"How to use the web as a platform for data collection, computation, and publishing. Accessing data via scraping and APIs. Using the cloud for tasks that are beyond the capability of your local computing resources.","['local computing resources', 'Accessing data', 'data collection', 'scraping', 'APIs', 'computation', 'capability', 'cloud', 'tasks', 'web', 'platform']","['Computer', 'Website', 'CERN', 'XML', 'World Wide Web', 'Computing', 'Google', 'Computation']",['cloud'],[],[]
69,Statistical Inference and Computation II,Methods for dealing with the multiple testing problem. Bayesian reasoning for data science. How to formulate and implement inference using the prior-to-posterior paradigm.,"['multiple testing problem', 'Bayesian reasoning', 'prior-to-posterior paradigm', 'data science']",['Scientific method'],[],[],[]
70,Advanced Machine Learning,"Advanced machine learning methods, with an undercurrent of natural language processing (NLP) applications. Bag of words, recommender systems, topic models, ranking, natural language as sequence data, POS tagging, CRFs for named entity recognition and RNNs for text synthesis. An introduction to popular NLP libraries in Python.","['popular NLP libraries', 'natural language', 'recommender systems', 'POS tagging', 'entity recognition', 'Advanced machine', 'sequence data', 'topic models', 'text synthesis', 'undercurrent', 'Bag', 'ranking', 'Python']","['Natural language processing', 'Machine learning', 'Named entity recognition', 'Computational linguistics', 'Learning', 'Natural language', 'Linguistics', 'Language', 'C', 'Tasks of Natural language processing', 'Set', 'Message Understanding Conference', 'Programming language']","['machine learning', 'natural language processing']",[],['Python']
71,Spatial and Temporal Models,Model fitting and prediction in the presence of correlation due to temporal and/or spatial association. ARIMA models and Gaussian processes.,"['ARIMA models', 'Gaussian processes', 'spatial association', 'correlation', 'prediction', 'presence']","['Model', 'Autoregressive integrated moving average', 'Normal distribution']",[],[],[]
72,Experimentation and Causal Inference,"Statistical evidence from randomized experiments versus observational studies. Applications of randomization, e.g., A/B testing for website optimization.","['randomized experiments', 'observational studies', 'Statistical evidence', 'A/B testing', 'website optimization', 'randomization']","['Randomized controlled trial', 'Design of experiments', 'Scientific method', 'Experimental design']",[],[],[]
73,Data Visualization II,"How to make principled and effective choices with respect to marks, spatial arrangement, and colour. Analysis, design, and implementation of interactive figures. How to provide multiple views, deal with complexity, and make difficult decisions about data reduction.","['spatial arrangement', 'effective choices', 'difficult decisions', 'data reduction', 'multiple views', 'interactive figures', 'respect', 'marks', 'colour', 'complexity', 'deal', 'Analysis', 'design']",['Design'],[],[],[]
74,Capstone Project,"A mentored group project based on real data and questions from a partner within or outside the university. Students will formulate questions and design and execute a suitable analysis plan. The group will work collaboratively to produce a project report, presentation, and possibly other products, such as a web application.","['mentored group project', 'suitable analysis plan', 'possibly other products', 'real data', 'web application', 'project report', 'partner', 'questions', 'university', 'Students', 'design']","['Project management', 'Web 2.0', 'University', 'Plan']",[],[],[]
75, Designs of Algorithms and Programming for Massive Data,"To introduce students to the theory and design of algorithms to acquire and process large dimensional data. Advanced data structures, graph algorithms,åÊand algebraic algorithms. Complexity analysis, complexity classes, and NP-completeness, approximation algorithms and parallel algorithms. Study of algorithmic techniques and modeling frameworks that facilitate the analysis of massively large amounts of data. Introduction to information retrieval, streaming algorithms and analysis of web searches and crawls.","['algorithms,åÊand algebraic algorithms', 'large dimensional data', 'massively large amounts', 'approximation algorithms', 'parallel algorithms', 'Advanced data structures', 'complexity classes', 'Complexity analysis', 'algorithmic techniques', 'modeling frameworks', 'information retrieval', 'web searches', 'NP-completeness', 'crawls', 'graph', 'students', 'theory', 'design']","['Algorithm', 'Computational complexity theory', 'Numerical analysis', 'Discrete mathematics', 'Parallel algorithm', 'Approximation algorithm', 'Web search engine', 'Computer program', 'Mathematical logic', 'Distributed algorithms', 'Algorithms', 'Graph theory', 'Algorithmic efficiency', 'Analysis of algorithms', 'Chess', 'Big O notation', 'Manifold', 'Mathematics', 'Computer', 'Information retrieval', 'Introduction', 'Computer science', 'RP', ""Kruskal's algorithm"", 'Deterministic algorithm', 'Parallel computing', 'NP-complete', 'Process architecture', 'Branch and bound']","['algorithms', 'algorithms', 'algorithms', 'algorithms', 'algorithms', 'algorithms']",[],[]
76, Machine Learning ,Overview of artificial learning systems. Supervised and unsupervised learning. Statistical models. Decision trees. Clustering. Feature extraction. Artificial neural networks. Reinforcement learning. Applications to pattern recognition Overview of artificial learning systems. Supervised and unsupervised learning. Statistical models. Decision trees. Clustering. Feature extraction. Artificial neural networks. Reinforcement learning. Applications to pattern recognition and data mining.,"['Artificial neural networks', 'artificial learning systems', 'Feature extraction', 'unsupervised learning', 'Decision trees', 'Statistical models', 'Reinforcement learning', 'data mining', 'Clustering', 'Applications', 'recognition']","['Machine learning', 'Pattern recognition', 'Artificial neural network', 'Neural network', 'Supervised learning', 'Unsupervised learning', 'Decision tree learning', 'Formal sciences', 'Artificial intelligence', 'Data', 'Predictive analytics']","['Supervised', 'unsupervised', 'Clustering', 'Supervised', 'unsupervised', 'Clustering']",[],[]
77, Management of Big Data and Big Data Tools,"The course will discuss data management techniques for storing and analyzing very large amounts of data. The emphasis will be on columnar databases and on Map Reduce as a tool for creating parallel algorithms that can process very large amounts of data. Big Data applications, Columnar stores, distributed databases, Hadoop, Locality Sensitive Hashing (LSH), Dimensionality reduction, Data streams, unstructured data processing, NoSQL, and NewSQL.åÊ","['Locality Sensitive Hashing', 'large amounts', 'data management techniques', 'unstructured data processing', 'Columnar stores', 'Big Data applications', 'columnar databases', 'Dimensionality reduction', 'parallel algorithms', 'Map Reduce', 'Data streams', 'Hadoop']","['Computer program', 'Data', 'Data management', 'Parallel algorithm', 'Parallel computing', 'Algorithm', 'MapReduce', 'Halting problem', 'Distributed algorithms']","['algorithms', 'Big Data', 'unstructured', 'NoSQL']",[],['Hadoop']
78, Data Mining and Prescriptive Analysis ,The course teaches to use data to recommend optimum course of action to achieve the optimum outcome and to formulate new products and services in a data driven manner. The course will cover all these issues and will illustrate the whole process by examples. Special emphasis will be given to data mining and computational techniques as well as optimization and stochastic optimization techniques.åÊ,"['stochastic optimization techniques.åÊ', 'optimum outcome', 'optimum course', 'new products', 'Special emphasis', 'computational techniques', 'data mining', 'manner', 'action', 'services', 'issues', 'process']","['Global optimization', 'Optimization', 'Data', 'Operations research']",[],[],[]
79," Soft Skills, Research and Communication ",The course will focus on communicating and presenting data analysis results. It aims at building the competency in story telling from the numbers.åÊ,"['data analysis results', 'competency', 'course', 'story', 'numbers.åÊ']","['Storytelling', 'Data']",[],[],[]
80,Major Research Project,"The student is required to conduct an applied advanced research project. The project will be carried out under the guidance of a supervisor.åÊ On completion of the project, the results are submitted in a technical report format to an examining committee and the student will make an oral presentation of the report to the committee for assessment and grading of the report.åÊ The student is expected to provide evidence of competence in the carrying out of a technical project and present a sound understanding of the material associated with the research project. This is a ÛÏMilestone.ÛåÊ","['technical report format', 'research project', 'oral presentation', 'sound understanding', 'technical project', 'student', 'committee', 'competence', 'completion', 'grading', 'guidance', 'evidence', 'supervisor.åÊ', 'results', 'assessment', 'report.åÊ']",['Research'],[],[],[]
81,Introduction to Data Science,"Data Science is a dynamic and fast growing field at the interface of Statistics and Computer Science. The emergence of massive datasets containing millions or even billions of observations provides the primary impetus for the field. Such datasets arise, for instance, in large-scale retailing, telecommunications, astronomy, and internet social media. This course will emphasize practical techniques for working with large-scale data. Specific topics covered will include statistical modeling and machine learning, data pipelines, programming languages, ""big data"" tools, and real world topics and case studies. The use of statistical and data manipulation software will be required. Course intended for non-quantitative graduate-level disciplines. This course will not count towards degree requirements for graduate programs such as Statistics, Computer Science, or Data Science. Students should inquire with their respective programs to determine eligibility of course to count towards minimum degree requirements. This course does not fulfill any major requirements for undergraduate degree programs offered by Computer Science.","['fast growing field', 'non-quantitative graduate-level disciplines', 'data manipulation software', 'real world topics', 'Data Science', 'undergraduate degree programs', 'minimum degree requirements', 'massive datasets', 'large-scale retailing', 'primary impetus', 'large-scale data', 'data pipelines', 'social media', 'practical techniques', 'big data', 'machine learning', 'programming languages', 'case studies', 'Specific topics', 'statistical modeling', 'respective programs', 'major requirements', 'graduate programs', 'course', 'Statistics', 'billions', 'instance', 'emergence', 'millions', 'observations', 'interface', 'eligibility', 'telecommunications', 'astronomy']","['Scientific method', 'Programming language', 'Mathematics', ""Bachelor's degree"", 'Computer program', 'Algorithm', 'Computer', 'Computer science', 'Postgraduate education', 'Electrical engineering', 'Statistics', 'Object-oriented programming', 'Data Manipulation Language', 'Artificial intelligence', 'Data set', 'Software engineering', 'SQL', 'Academic degree', 'Applied mathematics', 'Doctorate', 'Computational science', 'Undergraduate education', 'Academic degrees', 'Data', 'Computer programming', 'Higher education', 'Graduate school', 'Requirement', 'Case study', 'Field', 'Machine code', 'Islamic Golden Age', 'Undergraduate degree', 'Learning', 'University', 'Requirements analysis', 'Programmer']","['Statistics', 'machine learning', 'programming', 'big data', 'Statistics']",[],[]
82,Computer Systems for Data Science,"An introduction to computer architecture and distributed systems with an emphasis on warehouse scale computing systems. Topics will include fundamental tradeoffs in computer systems, hardware and software techniques for exploiting instruction-level parallelism, data-level parallelism and task level parallelism, scheduling, caching, prefetching, network and memory architecture, latency and throughput optimizations, specialization, and an introduction to programming data center computers.","['task level parallelism', 'instruction-level parallelism', 'data-level parallelism', 'scale computing systems', 'programming data center', 'fundamental tradeoffs', 'software techniques', 'memory architecture', 'latency', 'optimizations', 'caching', 'specialization', 'warehouse', 'introduction', 'scheduling', 'emphasis', 'Topics', 'hardware']","['Computer', 'Operating system', 'Software engineering', 'Computer program', 'Computer science', 'Computing', 'Von Neumann architecture', 'Computer data storage', 'Programmer', 'Computer programming']",['programming'],[],[]
83,Machine Learning for Data Science,"COMS 4721 is a graduate-level introduction to machine learning. The course covers basic statistical principles of supervised machine learning, as well as some common algorithmic paradigms. Additional topics, such as representation learning and online learning, may be covered if time permits.","['common algorithmic paradigms', 'graduate-level introduction', 'supervised machine', 'time permits', 'statistical principles', 'Additional topics', 'machine learning', 'representation learning', 'online learning', 'COMS']","['Supervised learning', 'Machine learning']","['machine learning', 'supervised', 'machine learning']",[],[]
84,Algorithms for Data Science,"Methods for organizing data, e.g. hashing, trees, queues, lists, priority queues. Streaming algorithms for computing statistics on the data. Sorting and searching. Basic graph models and algorithms for searching, shortest paths, and matching. Dynamic programming. Linear and convex programming. Floating point arithmetic, stability of numerical algorithms, Eigenvalues, singular values, PCA, gradient descent, stochastic gradient descent, and block coordinate descent. Conjugate gradient, Newton and quasi-Newton methods. Large scale applications from signal processing, collaborative filtering, recommendations systems, etc.","['stochastic gradient descent', 'Basic graph models', 'priority queues', 'Large scale applications', 'Conjugate gradient', 'e.g. hashing', 'numerical algorithms', 'shortest paths', 'singular values', 'convex programming', 'collaborative filtering', 'Dynamic programming', 'signal processing', 'recommendations systems', 'quasi-Newton methods', 'data', 'Eigenvalues', 'PCA', 'stability', 'Linear', 'trees', 'lists']","['Numerical analysis', 'Optimization algorithms', 'Floating point', 'Optimization', 'Mathematics', 'Graph theory', 'Computer', 'Algorithm', 'Gradient descent', 'Function', 'Computer program', 'Shortest path problem', 'Fixed-point arithmetic', 'Computing', 'Path', ""Newton's method in optimization"", 'Rational number', 'Derivative', 'Fortran', 'Computer science', 'Quadratic programming', 'Convex optimization']","['algorithms', 'statistics', 'descent', 'algorithms', 'programming', 'Linear', 'programming', 'algorithms', 'gradient', 'descent', 'gradient']",[],[]
85,Probability Theory,"A calculus-based introduction to probability theory. Topics covered include random variables, conditional probability, expectation, independence, Bayes' rule, important distributions, joint distributions, moment generating functions, central limit theorem, laws of large numbers and Markov's inequality.","['moment generating functions', 'central limit theorem', 'conditional probability', 'probability theory', 'calculus-based introduction', 'important distributions', 'joint distributions', 'random variables', 'large numbers', 'expectation', 'Bayes', 'inequality', 'Markov', 'independence', 'rule', 'Topics']","['Probability theory', 'Probability', 'Event', 'Random variable', 'Variance', 'Conditional probability', 'Probability space', 'Probability density function', 'Expected value', ""Bayes' theorem"", 'Law of large numbers', 'Moment']","['probability', 'probability']",[],[]
86,Probability & Statistics for Data Science,"This course covers the following topics: Fundamentals of probability theory and statistical inference used in data science; Probabilistic models, random variables, useful distributions, expectations, law of large numbers, central limit theorem; Statistical inference; point and confidence interval estimation, hypothesis tests, linear regression.","['confidence interval estimation', 'central limit theorem', 'statistical inference', 'random variables', 'Probabilistic models', 'linear regression', 'probability theory', 'useful distributions', 'following topics', 'hypothesis tests', 'data science', 'large numbers', 'expectations', 'Fundamentals', 'course', 'law']","['Statistics', 'Statistical inference', 'Probability theory', 'Probability', 'Confidence interval', 'Theory', 'Variance', 'Event', 'Mathematics', 'Random variable', 'Statistical hypothesis testing', 'Interval estimation', 'Probability space', 'Normal distribution', 'Prediction interval', 'Stochastic process', 'Scientific method', 'Decision theory', 'Experiment', 'Expected value', 'Estimation theory', 'Central limit theorem', 'Theorem', 'Credible interval', 'Applied mathematics', 'Probability and statistics', 'Inference', 'Probability density function', 'Regression analysis', 'Probabilistic logic', 'Linear regression', 'Nuisance parameter', 'Convergence of random variables', 'Law of large numbers', 'Function', 'Integral']","['probability', 'regression']",[],[]
87,Exploratory Data Analysis & Visualization,"Fundamentals of data visualization, layered grammar of graphics, perception of discrete and continuous variables, introduction to Mondran, mosaic pots, parallel coordinate plots, introduction to ggobi, linked pots, brushing, dynamic graphics, model visualization, clustering and classification.","['parallel coordinate plots', 'mosaic pots', 'data visualization', 'continuous variables', 'model visualization', 'dynamic graphics', 'Fundamentals', 'clustering', 'perception', 'grammar', 'introduction', 'Mondran']","['Computer graphics', 'Graphic design']","['data visualization', 'visualization', 'clustering']",[],[]
88,Statistical Inference & Modeling,"Course covers fundamentals of statistical inference and testing, and gives an introduction to statistical modeling. The first half of the course will be focused on inference and testing, covering topics such as maximum likelihood estimates, hypothesis testing, likelihood ratio test, Bayesian inference, etc. The second half of the course will provide introduction to statistical modeling via introductory lectures on linear regression models, generalized linear regression models, nonparametric regression, and statistical computing. Throughout the course, real-data examples will be used in lecture discussion and homework problems.","['linear regression models', 'generalized linear regression', 'maximum likelihood estimates', 'likelihood ratio test', 'statistical inference', 'Bayesian inference', 'statistical modeling', 'nonparametric regression', 'hypothesis testing', 'homework problems', 'introductory lectures', 'lecture discussion', 'real-data examples', 'statistical computing', 'half', 'course', 'introduction', 'fundamentals']","['Statistical inference', 'Statistical theory', 'Regression analysis', 'Linear regression', 'Likelihood function', 'Bayesian inference', 'Estimation theory', 'Generalized linear model', 'Bayes factor', 'Logic and statistics', 'Scientific method', 'Likelihood principle', 'Maximum likelihood', 'Statistics', 'Nonparametric regression', 'Likelihood-ratio test', 'Confidence interval', 'Decision theory', ""Bayes' theorem"", 'Bayesian statistics', 'Psychometrics', 'Statistical hypothesis testing', 'Null hypothesis', 'Statistical significance']","['regression', 'regression', 'regression']",[],[]
89,Translational Bioinformatics,"MS students are encouraged to explore courses offered across the university and take advantage of the expertise in a wide range of disciplines at Columbia. Prior to registration, students receive advisement to determine if a course of interest is relevant and meets the criteria of a 4000-level or higher, technical course completed for a letter grade. You're welcome to explore the CU Directory of Classes for possible courses: http://www.columbia.edu/cu/bulletin/uwb/","['CU Directory', 'wide range', 'MS students', 'technical course', 'possible courses', 'advisement', 'advantage', 'disciplines', 'criteria', 'university', 'expertise', 'Columbia', 'registration', 'letter', 'grade', 'Classes']",[],[],[],[]
90,Topics in Computer Science: Applied Machine Learning,"Please note that many departments, including DSI, give registration priority to their students.åÊ Space permitting, courses are then opened up to students outside the department.","['registration priority', 'students.åÊ Space', 'DSI', 'note', 'departments', 'courses', 'department']",['Department store'],[],[],[]
91,Topics in Computer Science: Causal Inference for Data Science,ELECTIVE EXAMPLESThe following courses are examples of classes that MS students have used for elective credit. Courses offerings are dependent on faculty availabilty and may vary each semester. ,"['ELECTIVE EXAMPLESThe following', 'elective credit', 'Courses offerings', 'faculty availabilty', 'semester', 'classes', 'students']",[],[],[],[]
92,Topics in Computer Science: Elements of Data Science: A First Course,"Methods in biomedical data science (i.e. translational bioinformatics) for graduate students and upperclassmen. Students study the statistical and computational algorithms to evaluate large biomedical data, including sequence analysis, application of supervised and unsupervised machine learning, graph theoretic models and network analysis, and chemical informatics. They study how to apply these algorithms to biomedical domains in non-human genetics, human genetics, pharmacology, and public health. Successful completion of the course readies the student for graduate level research in translational bioinformatics.","['biomedical data science', 'translational bioinformatics', 'large biomedical data', 'graph theoretic models', 'graduate level research', 'biomedical domains', 'unsupervised machine', 'computational algorithms', 'Successful completion', 'non-human genetics', 'chemical informatics', 'sequence analysis', 'graduate students', 'network analysis', 'public health', 'human genetics', 'upperclassmen']","['Computer science', 'Algorithm', 'Scientific method', 'Science', 'Health', 'Machine learning', 'Bioinformatics', 'Computer program', 'Discrete mathematics', 'Graduate school', 'Unsupervised learning', 'Human', 'Learning', 'Mathematical analysis', 'Biostatistics', 'Cauchy sequence', 'Computer', 'Mathematics', 'Education', 'Statistics', 'Cheminformatics', 'Genomics', 'Greek loanwords', 'Genetics', 'Artificial intelligence', 'Graph theory', 'Genetic algorithm', 'Human genome', 'Theoretical computer science', 'Student', 'Computational science', 'Humans', 'Computational learning theory', 'Cognitive science']","['algorithms', 'supervised', 'unsupervised', 'machine learning', 'algorithms']",[],[]
93,Topics in Computer Science: Machine Learning Products for Data Science,"This class offers a hands-on approach to machine learning and data science. The class discusses the application of machine learning methods like SVMs, Random Forests, Gradient Boosting and neural networks on real world dataset, including data preparation, model selection and evaluation. This class complements COMS W4721 in that it relies entirely on available open source implementations in scikit-learn and tensor flow for all implementations. Apart from applying models, we will also discuss software development tools and practices relevant to productionizing machine learning models.","['real world dataset', 'open source implementations', 'software development tools', 'Gradient Boosting', 'hands-on approach', 'Random Forests', 'tensor flow', 'data science', 'neural networks', 'model selection', 'data preparation', 'SVMs', 'class', 'COMS', 'models', 'machine', 'application', 'methods', 'evaluation']","['Machine learning', 'Computer program', 'Learning', 'Statistical classification', 'Memory leak']","['machine learning', 'machine learning', 'Random Forests', 'machine learning']",[],[]
94,NLP: Computational Models of Social Meaning,"This course is designed as an introduction to elements that constitutes the skill set of a data scientist. The course will focus on the utility of these elements in common tasks of a data scientist, rather than their theoretical formulation and properties. The course provides a foundation of basic theory and methodology with applied examples to analyze large engineering, business, and social data for data science problems. Hands-on experiments with R or Python will be emphasized.","['data scientist', 'data science problems', 'skill set', 'theoretical formulation', 'Hands-on experiments', 'common tasks', 'basic theory', 'large engineering', 'social data', 'course', 'elements', 'methodology', 'Python', 'introduction']","['Science', 'Scientific method', 'Theory', 'Experiment', 'Physics', 'Mathematics', 'Hypothesis', 'Empiricism', 'Chemistry', 'Engineering', 'Research', 'Economics', 'Falsifiability', 'Fact', 'Prime number']",[],[],"['R', 'Python']"
95,Topics in Computer Science: Projects in Data Science: A First Course,This applied Natural Language Processing course will focus on computational methods for extracting social and interactional meaning from large volumes of text and speech (both traditional media and social media). Topics will include:,"['Natural Language Processing', 'interactional meaning', 'large volumes', 'computational methods', 'traditional media', 'social media', 'course', 'text', 'speech']","['Linguistics', 'Semantics']",['Natural Language Processing'],[],[]
96,Topics in Information Processing: Big Data Analytics,"Instructors: Patrick Houlihan, David ShilaneThis course will introduce students to the practice of Data Science. Across many practice areas, Data Science is applied to generate knowledge and improve the quality of products and services. The form of this work can incorporate a wide variety of information sources, analytical methods, technological systems, and reporting formats. This course will provide exposure to the tools and techniques of Data Science while exploring a number of representative Practice Areas, Methods, and Software Skills","['Data Science', 'David ShilaneThis course', 'representative Practice Areas', 'Patrick Houlihan', 'technological systems', 'wide variety', 'information sources', 'Software Skills', 'analytical methods']","['Science', 'Technology', 'Scientific method', 'Epistemology', 'The Practice']",[],[],[]
97,"Topics in Information Processing: Deep Learning for Computer Vision, Speech, and Language","With the advance of IT storage, processing, computation, and sensing technologies, Big Data has become a novel norm of life. Only until recently, computers are able to capture and analysis all sorts of large-scale data from all kinds of fields -- people, behavior, information, devices, sensors, biological signals, finance, vehicles, astronology, neurology, etc. Almost all industries are bracing into the challenge of Big Data and want to dig out valuable information to get insight to solve their challenges. This course shall provide the fundamental knowledge to equip students being able to handle those challenges. This discipline inherently involves many fields. Because of its importance and broad impact, new software and hardware tools and algorithms are quickly emerging. A data scientist needs to keep up with this ever changing trends to be able to create a state-of-the-art solution for real-world challenges.","['Big Data', 'novel norm', 'real-world challenges', 'biological signals', 'equip students', 'large-scale data', 'valuable information', 'fundamental knowledge', 'state-of-the-art solution', 'data scientist', 'broad impact', 'new software', 'hardware tools', 'fields', 'sorts', 'computation', 'neurology', 'discipline', 'advance', 'kinds', 'sensors', 'storage', 'processing', 'technologies', 'life', 'insight', 'computers', 'people', 'behavior', 'devices', 'finance', 'vehicles', 'astronology', 'importance', 'trends']","['Computer', 'Want', 'Life', 'Need', 'WANT', 'Challenge', 'Computer program']","['Big Data', 'Big Data', 'algorithms']",[],[]
98,Topics in Quantitative Finance: Big Data in Finance,"The vast proliferation of data and increasing technological complexities continue to transform the way industries operate and compete. Over the last two years, 90 percent of the data in the world has been created as a result of the creation of 2.5 quintillion bytes of data on a daily basis. Commonly referred to as big data, this rapid growth and storage creates opportunities for collection, processing and analysis of structured and unstructured data. Financial services, in particular, have widely adopted big data analytics to inform better investment decisions with consistent returns. In conjunction with big data, algorithmic trading uses vast historical data with complex mathematical models to maximize portfolio returns. The continued adoption of big data will inevitably transform the landscape of financial services. However, along with its apparent benefits, significant challenges remain in regards to big dataÛªs ability to capture the mounting volume of data. The increasing volume of market data poses a big challenge for financial institutions. Along with vast historical data, banking and capital markets need to actively manage ticker data. Likewise, investment banks and asset management firms use voluminous data to make sound investment decisions. Insurance and retirement firms can access past policy and claims information for active risk management. The course will be a mix of Theory and practice with real big data cases in finance. We will invite guest lecturers mostly for real Big Data Finance Applications. We will give MATLAB, R or Python examples.","['big data', 'vast historical data', 'real big data', 'big data analytics', 'Big Data Finance', 'big data cases', 'better investment decisions', 'financial services', 'big data\x89Ûªs ability', 'complex mathematical models', 'sound investment decisions', 'asset management firms', 'active risk management', 'vast proliferation', 'unstructured data', 'voluminous data', 'ticker data', 'market data', 'technological complexities', 'way industries', 'consistent returns', 'daily basis', 'portfolio returns', 'big challenge', 'apparent benefits', 'algorithmic trading', 'continued adoption', 'rapid growth', 'guest lecturers', 'financial institutions', 'significant challenges', 'capital markets', 'investment banks', 'Python examples', 'retirement firms', 'volume', 'regards', 'percent', 'bytes', 'world', 'creation', 'result', 'conjunction', 'storage', 'opportunities', 'collection', 'processing', 'analysis', 'MATLAB', 'landscape', 'banking', 'Applications', 'Insurance', 'policy']","['Investment', 'Financial services', 'Investment management', 'Corporate finance', 'Finance', 'Bank', 'Risk', 'Insurance', 'Financial markets', 'Economics', 'Business intelligence', 'Data analysis', 'Capital', 'Bond', 'Unstructured data', 'Collective investment scheme', 'Management']","['big data', 'structured', 'unstructured', 'big data', 'big data', 'big data', 'big data', 'Big Data']",[],"['Python', 'MATLAB', 'R']"
99,Topics in Modern Statistics: Applied Machine Learning for Financial Modeling and Forecasting,"The course focuses on translating technical expertise into work-place solutions by teaching students to: (1) identify relevant shortfalls inåÊ traditional processes; (2) precisely match datasets and machine learning features to overcome these shortfalls; (3) narrowly define value to fit work place processes, analytical framework, and bottom line.åÊ Each class will be structured as an actual end-to-end work-place project and use concrete examples to teach students to design, build and deliver solutionsåÊ that integrate these considerations. A combination of assignments, presentation, and research paper will be sued to evaluation students' progress in bridging technical and applied solutions with evaluation criteria matching those of a work-place project.","['actual end-to-end work-place', 'work-place project', 'relevant shortfalls', 'work place', 'analytical framework', 'technical expertise', 'concrete examples', 'traditional processes', 'work-place solutions', 'research paper', 'evaluation criteria', 'applied solutions', 'evaluation students', 'datasets', 'considerations', 'assignments']","['Education', 'Learning', 'Research', 'Match', 'Teacher', 'Project management']","['machine learning', 'structured']",[],[]
100,Topics in Modern Statistics: Applied Machine Learning for Image Analysis,"Images are everywhere. How to deal with image data, especially with big data, is an urgent problem for data analysts.åÊ Machine learning has proven to be a powerful technology to process and analyze such big data.åÊ The course will discuss how machine learning methods are use in the field of image analysis, including biometrics (iris and face recognition), natural images (object identification/recognition), brain images (encoding and decoding), and handwritten digit recognition.åÊ Students will learn how to sue traditional machine learning methods in image data processing and analysis, and develop techniques to improve these methods.åÊ The aim of this course is to prepare students with basis knowledge and skills to explore opportunities using machine learning in the field of image analysis.","['handwritten digit recognition.åÊ', 'data analysts.åÊ Machine', 'machine learning methods', 'image data processing', 'image analysis', 'urgent problem', 'powerful technology', 'object identification/recognition', 'basis knowledge', 'natural images', 'big data', 'brain images', 'traditional machine', 'course', 'field', 'students', 'biometrics', 'iris', 'aim', 'techniques']","['Learning', 'Machine learning', 'Knowledge', 'Skill', 'Education', 'Pattern recognition', 'Biometrics', 'Data', 'Computer graphics']","['big data', 'Machine learning', 'machine learning', 'machine learning', 'machine learning']",[],[]
101,Sustainability Technology and the Evolution of Smart Cities,"This course is offered through the School of Continuing Education. The progress of sustainability in recent years has almost entirely been a result in the evolution of smart, sustainable technology solutions. This course examines opportunities to drive sustainability through technology applications with the end goal of piecing together all of the pieces to envision an intelligent city. Companies are increasingly turning to technology to fulfill their sustainability goals considering many technologies provide off-the-shelf, cost-effective and immediate savings compared to operationally invasive, resource-heavy sustainability transformation programs. Sustainability technology ranges from intelligent infrastructure to mobile applications that help to drive the ""sharing economy"". The course will provide an overview of the sustainability technologies that large corporations are actively pursuing and delve into the project management and integration strategies required to implement these solutions. Successful sustainability practitioners must not only have a strong understanding of the values and methodologies of sustainable operations, but also the tools and technologies available to drive sustainability throughout their organization. Upon completion of the class, students will have a sufficient level of understanding to discuss these solutions and relevant case studies with potential employers. This course will benefit anyone interested in a career in sustainability or in smart cities as it will provide them the skills and analytical capabilities to analyze which sustainability technologies are a good fit for their company's sustainability and growth strategy.","['resource-heavy sustainability transformation', 'Successful sustainability practitioners', 'sustainability technologies', 'sustainability goals', 'Sustainability technology', 'sustainable technology solutions', 'relevant case studies', 'Continuing Education', 'intelligent city', 'end goal', 'immediate savings', 'intelligent infrastructure', 'technology applications', 'sufficient level', 'large corporations', 'project management', 'integration strategies', 'smart cities', 'good fit', 'analytical capabilities', 'sustainable operations', 'potential employers', 'strong understanding', 'course', 'School', 'result', 'methodologies', 'completion', 'evolution', 'opportunities', 'pieces', 'Companies', 'programs', 'economy', 'overview', 'progress', 'career', 'skills', 'tools', 'organization', 'company']","['City', 'Sustainability', 'Appropriate technology', 'Sustainable living', 'Intelligent city', 'Smart city', 'Economy', 'Engineering', 'Neolithic', 'Design', 'Ecological economics', 'Biodiversity', 'Technology', 'Sustainable architecture', 'Industrial ecology', 'Information technology', 'Sustainable development', 'Case study', 'Strategy', 'Goal', 'Economic growth']",[],[],[]
102,Data Science Capstone & Ethics,"This course provides a unique opportunity for students in the M.S. in Data Science program to apply their knowledge of the foundations, theory and methods of data science to address data science problems in industry, government and the non-profit sector. The course activities focus on a semester-length data science project sponsored by a faculty member or local organization. The project synthesizes the statistical, computational, engineering challenges and social issues involved in solving complex real-world problems.","['data science', 'Data Science program', 'complex real-world problems', 'data science problems', 'semester-length data science', 'non-profit sector', 'unique opportunity', 'engineering challenges', 'faculty member', 'local organization', 'social issues', 'course', 'project', 'foundations', 'students', 'M.S.', 'knowledge', 'theory', 'methods', 'industry']","['Science', 'Mathematics', 'Scientific method', 'Sociology', 'Non-profit organization', 'Physics', 'Problem solving', 'Epistemology', 'Data', 'Experiment', 'Computer', 'Machine code', 'Theory', 'Statistics', 'University']",[],[],[]
103, Data Science Visualization Lab,"Take in conjunction with HCDE 511: Information Visualization, this class provides students with additional opportunities to practice and discuss data visualization concepts, with an emphasis on user-centered design (UCD) approaches and software development. Students åÊwork in small groups on structured data visualization exercises and UCD methods and to implement simple visualizations.","['data visualization concepts', 'data visualization exercises', 'Information Visualization', 'UCD methods', 'simple visualizations', 'additional opportunities', 'software development', 'small groups', 'conjunction', 'approaches', 'students', 'HCDE', 'class']","['Design', 'Graphic design', 'Visualization', 'Visualization', 'Information visualization', 'Software engineering']","['Visualization', 'data visualization', 'structured data', 'visualization']",[],[]
104, Human-Centered Data Science,This course focuses on fundamental principles of data science and its human implications. WeÛªll cover data ethics; data privacy; differential privacy; algorithmic bias; legal frameworks and intellectual property; provenance and reproducibility; data curation and preservation; user experience design and usability testing for big data; ethics of crowdwork; data communication; and societal impacts of data science.,"['user experience design', 'differential privacy', 'data science', 'algorithmic bias', 'societal impacts', 'human implications', 'data privacy', 'fundamental principles', 'data curation', 'legal frameworks', 'usability testing', 'intellectual property', 'data ethics', 'big data', 'data communication', 'reproducibility', 'provenance']","['Design', 'Experience design', 'Human factors', 'User interface', 'User experience design', 'Usability', 'Human-computer interaction', 'Scientific method', 'Law', 'Science', 'Privacy', 'Web design', 'Computer science', 'Technology', 'Interaction design', 'Religion', 'Intellectual property', 'User experience']",['big data'],[],[]
105, Data Management for Data Science,This course introduces students to database management systems and techniques that use these systems. Topics covered include data models; query languages; database tuning and optimization; data warehousing; and parallel processing.,"['query languages', 'parallel processing', 'database tuning', 'data warehousing', 'management systems', 'data models', 'course', 'students', 'techniques', 'Topics']","['Database management system', 'Data modeling', 'Data management', 'Relational database management system', 'Database']","['database', 'database']",[],[]
106, Software Design for Data Science,"This course introduces students to software design and engineering practices and concepts, including version control, testing and automatic build management.","['automatic build management', 'engineering practices', 'version control', 'course', 'students', 'design', 'concepts', 'testing']","['Design', 'Software engineering', 'Software development process', 'Civil engineering', 'Control', 'Design management']",[],[],[]
107, Scalable Data Systems & Algorithms,"This course focuses on principles and algorithms for data management and analysis at scale. WeÛªll cover designs of and how to use traditional and modern big data systems, as well as the basics of cloud computing.","['We\x89Ûªll cover designs', 'modern big data', 'cloud computing', 'data management', 'algorithms', 'basics', 'course', 'principles', 'analysis', 'scale']",['Computer'],"['algorithms', 'big data', 'cloud']",[],[]
108, Introduction to Statistics & åÊProbability,"In this course, youÛªll get an overview of probability; conditional probability and independence; BayesÛª theorem; discrete and continuous random variables, including jointly distributed random variables; key distributions, including normal distribution and its spin-offs; properties of expectation and variance; conditional expectation; covariance and correlation; central limit theorem; law of large numbers; and parameter estimation.","['continuous random variables', 'central limit theorem', 'conditional expectation', 'conditional probability', 'Bayes\x89Ûª theorem', 'parameter estimation', 'key distributions', 'normal distribution', 'large numbers', 'covariance', 'spin-offs', 'variance', 'correlation', 'independence', 'course', 'overview', 'properties']","['Probability theory', 'Variance', 'Probability density function', 'Random variable', 'Probability distribution', 'Normal distribution', 'Probability', 'Continuous probability distribution', 'Event', 'Probability space', 'Central limit theorem', 'Moment', 'Expected value', 'Estimator', 'Cumulative distribution function', 'Discrete probability distribution', 'Cauchy distribution', 'Standard deviation', 'Conditional probability', 'Probability and statistics', 'Conditional expectation', 'Estimation theory', 'Maximum likelihood', 'Law of large numbers', 'Binomial distribution', 'Distribution', 'Covariance', 'Topology', 'Expectation-maximization algorithm', 'Covariance and correlation', 'Exponential distribution', 'Kolmogorov–Smirnov test', 'Distributor']","['probability', 'probability']",[],[]
109, Applied Statistics & Experimental Design,"This course focuses on inferential statistical methods for discrete and continuous random variables, including tests for difference in means and proportions; linear and logistic regression; causation versus correlation; confounding; resampling methods; and study design.","['continuous random variables', 'inferential statistical methods', 'logistic regression', 'study design', 'proportions', 'causation', 'correlation', 'discrete', 'difference', 'means', 'course']","['Probability theory', 'Statistics', 'Regression analysis', 'Random variable', 'Probability distribution', 'Discrete probability distribution', 'Correlation does not imply causation', 'Mathematics', 'Chaos theory', 'Continuous probability distribution', 'Probability density function']",['regression'],[],[]
110, Statistical Machine Learning for Data Scientists,"This course covers bias-variance trade-off; training versus test error; overfitting; cross-validation; subset selection methods; regularized approaches for linear/logistic regression: ridge and lasso; non-parametric regression: trees, bagging, random forests; local regression and splines; generalized additive models; support vector machines; k-means and hierarchical clustering; and principal components analysis.","['non-parametric regression', 'subset selection methods', 'support vector machines', 'linear/logistic regression', 'principal components analysis', 'local regression', 'bias-variance trade-off', 'hierarchical clustering', 'random forests', 'test error', 'additive models', 'cross-validation', 'k-means']","['Machine learning', 'Regression analysis', 'Support vector machine', 'Principal component analysis', 'Nonparametric regression', 'K-means clustering', 'Data mining', 'Ring', 'Karl Pearson', 'Singular value decomposition', 'Hierarchy']","['regression', 'regression', 'regression', 'clustering']",[],[]
111, Data Science Capstone I - Project Preparation,"This course is part one of a two-course capstone sequence where students organize project teams, select project topics, write a project proposal and begin preparing project data sets.","['two-course capstone sequence', 'select project topics', 'project data sets', 'project proposal', 'project teams', 'students']","['Education', 'Data set']",[],[],[]
112, Data Science Capstone II - Project Implementation,"This course is part two of a two-course capstone sequence designed to build upon the student-driven project from DATA 590. Students synthesize and apply knowledge and techniques acquired throughout the Master of Science in Data Science program for åÊworking with large data sets, deriving insights from data and sharing insights with other people.","['two-course capstone sequence', 'large data sets', 'Data Science program', 'student-driven project', 'insights', 'Students', 'knowledge', 'techniques', 'Master']","[""Master's degree"", 'Project management', 'Scientific method']",[],[],[]
113, Information Visualization,"This course covers the design and presentation of digital information, teaching students how to use graphics, animation, sound and other modalities to present information to users. You'll also learn about vision and perception; methods for presenting complex information to enhance comprehension and analysis; and how to incorporate åÊvisualization techniques into human-computer interfaces.","['human-computer interfaces', 'teaching students', 'digital information', 'åÊvisualization techniques', 'complex information', 'modalities', 'comprehension', 'perception', 'course', 'design', 'presentation', 'graphics', 'animation', 'sound', 'users', 'vision', 'methods']","['Education', 'Graphic design', 'Psychology', 'Digital physics', 'Logic', 'Digital', 'Information', 'Cognitive science', 'Perception', 'Understanding', 'Complex analysis']",[],[],[]
114, Residency one: Orientation,"Orientation at Houston CityCentre, Houston, TX1. Technology overview2. Introduction to teams3. Introduction to programming and logic4. Statistics refresher5. Tableau, JMP & SAS training6. Conflict management assessment7. Project Management: Student panel on capstone8. Program Overview","['Conflict management assessment7', 'SAS training6', 'Technology overview2', 'Houston CityCentre', 'Student panel', 'Program Overview', 'Project Management', 'Tableau', 'JMP', 'Orientation', 'Introduction', 'TX1', 'Statistics', 'programming', 'logic4']","['Project management', 'Management', 'Conflict management']","['programming', 'Statistics']",['Management'],"['Tableau', 'SAS']"
115,Regression Analysis ,"Prepare data for model fitting, fit appropriate regression models to business data from a wide variety of settings, interpret the output from regression models, identify weaknesses in models and formulate ways to overcome them, make valid inferences and draw business conclusions on the basis of the fitted models, and recommend business actions on the basis of these conclusions. Topics covered in STAT 6081. Regression methods based on least squares2. Diagnostic methods including marginal model plots 3. Transformations and weighted least squares 4. Shrinkage and model selection techniques including lasso5. Linear regression splines including MARS6. Logistic regression7. Poisson regression8. Regression models with serially correlated errors9. Bayesian approaches to linear and logistic regression In STAT 608, students undertake a major project focused on building and interpreting one or more predictive models. Previous projects have focused on 1. Modeling the asking price of certified pre-owned BMW and Lexus automobiles2. Modeling default probability in 30 year mortgages for single family homes using the Freddie Mac data 3. Modeling price and customer ratings of Airbnb apartment stays in New York City, Paris and San Francisco4. Modeling price and popularity of New York City restaurants5. Modeling property assessment values for condominium units across different wards in Boston","['regression models', 'New York City', 'Linear regression splines', 'Regression methods', 'serially correlated errors9', 'logistic regression', 'marginal model plots', 'model selection techniques', 'Freddie Mac data', 'York City restaurants5', 'certified pre-owned BMW', 'single family homes', 'property assessment values', 'business conclusions', 'valid inferences', 'fitted models', 'Logistic regression7', 'model fitting', 'Prepare data', 'business data', 'weighted least squares', 'wide variety', 'business actions', 'predictive models', 'Diagnostic methods', 'different wards', 'Previous projects', 'condominium units', 'Bayesian approaches', 'default probability', 'Lexus automobiles2', 'major project', 'Airbnb apartment', 'customer ratings', 'San Francisco4', 'STAT', 'price', 'basis', 'Poisson', 'weaknesses', 'Shrinkage', 'Transformations', 'Topics', 'ways', 'settings', 'output', 'popularity', 'MARS6']","['Regression analysis', 'Least squares', 'Linear regression', 'New York City', 'Model', 'Statistical inference', 'Multivariate adaptive regression splines', 'Logistic regression', 'Housing cooperative', 'Generalized linear model', 'Honda Fit', 'New York', 'Real estate', 'Language interpretation', 'U.S. state', 'Inference', 'Bayesian inference', 'Single-family detached home', 'Curve fitting', 'Forecasting', 'Logistic function', 'Ordinary least squares', 'Bayesian information criterion', 'Apartment', 'City of London']","['regression', 'regression', 'probability', 'Modeling', 'Modeling', 'Modeling', 'Regression', 'Linear', 'regression', 'Logistic', 'Regression', 'regression', 'Modeling', 'Modeling']",[],[]
116,Business Data Base Sys. ,"The primary objective of the course is to familiarize students with general database concepts, database design methodologies, and database implementation. In addition, the course introduces students to Hadoop as a distributed data storage technology used by companies to process large data sets and to Python as a computer coding language used to obtain data from social media.Topics:1. Introduction to relational databases and SQL2. How to retrieve data from two or more tables3. How to code summary queries4. How to insert, update, and delete data5. How to work with data types6. How to work with functions7. How to work with the views8. Introduction to coding and coding standards and Python9. Core objects, variables, input, and output in Python10. Structures that control flow in Python11. Functions in Python12.Processing data in Python13. Miscellaneous topics in Python","['database design methodologies', 'general database concepts', 'data storage technology', 'large data sets', 'primary objective', 'delete data5', 'database implementation', 'relational databases', 'social media.Topics', 'summary queries4', 'data types6', 'Miscellaneous topics', 'Python12.Processing data', 'Core objects', 'Hadoop', 'SQL2', 'course', 'students', 'Introduction', 'variables', 'addition', 'input', 'companies', 'output', 'language', 'tables3', 'functions7', 'views8', 'standards', 'Python9', 'Functions', 'Python13', 'Structures']","['Relational model', 'SQL', 'Database', 'Database theory', 'Relation', 'Relational database', 'Output', 'Databases', 'Computer program', 'Relational algebra', 'Computer data storage', 'Input/output', 'Control theory', 'Code', 'Data management', 'Programming language', 'Introduction', 'Database model', 'Object', 'Flowchart', 'Data', 'Input', 'Process', 'Source code', 'Database trigger', 'Computer programming']","['database', 'database', 'database']",[],"['Hadoop', 'Python', 'Python']"
117,Practicum ,The student will learn:1. Teamwork and team effectiveness2. Understanding Big Data3. Ethics4. Project Management,"['Big Data3', 'team effectiveness2', 'Project Management', 'Teamwork', 'student', 'Ethics4']","['Project management', 'Project', 'Management']",[],"['team', 'Management']",[]
118,Methods in Multivariate Analysis ,"This course introduces foundations of multivariate analysis including matrix algebra, random vectors, multivariate distributions, and statistical inference for multivariate data. It also introduces methods of machine learning including principal component analysis, discriminant analysis, clustering, and elements of factor analysis and canonical analysis.Topics covered:1. Graphical techniques2. Principal component analysis3. Cluster analysis4. Correspondence analysis and other ordination techniques5. Discriminant analysis6. Classification and prediction7. Factor analysis and SEM8. Inference on mean vectors9. Canonical correlation analysis","['principal component analysis', 'Canonical correlation analysis', 'multivariate distributions', 'Principal component analysis3', 'factor analysis', 'multivariate analysis', 'multivariate data', 'discriminant analysis', 'statistical inference', 'Discriminant analysis6', 'canonical analysis.Topics', 'random vectors', 'matrix algebra', 'Graphical techniques2', 'Cluster analysis4', 'ordination techniques5', 'mean vectors9', 'Correspondence analysis', 'clustering', 'foundations']","['Multivariate statistics', 'Principal component analysis', 'Statistics', 'Factor analysis', 'Linear discriminant analysis', 'Vector space', 'Machine learning', 'Psychometrics', 'Data analysis', 'Ring', 'Canonical correlation', 'Mathematics', 'Matrix', 'Hilbert space', 'Multiple correspondence analysis', 'Singular value decomposition', 'Euclidean vector', 'Linear algebra', 'Determinant', 'Market research', 'Covariance and correlation', 'Field', 'The Unscrambler', 'Data mining', 'Multiplication', 'Group', 'Kernel principal component analysis', 'Geometry', 'Greek mathematics', 'Probability theory', 'Standard deviation', 'Educational psychology', 'Scientific method', 'Learning', 'Statistical inference', 'Multivariate analysis', 'Inference']","['machine learning', 'clustering']",[],[]
119,Marketing Engineering ,"This course will introduce students to a variety of datasets and teach them (hands on usage of) SAS to implement various quantitative techniques. This is an applied course that involves extensive use of data and PC-based analysis using JMP/SAS, a popular statistical software. The course will cover a number of quantitative analyses, explanatory and predictive models pertinent to marketing, such as customer segmentation, customer choice models, customer lifetime value, conjoint models, and market response models.Course Goals Understand how the ÛÏfirst principlesÛ of marketing strategy helps firms organize the analytics opportunity and challenge in todayÛªs data era, and use and execute data analytic techniques, and case studies to understand how to solve marketing analytics problems in a scientific and process-driven manner. Using statistical software to estimate various marketing models. Apply your learning through real database/marketing engineering cases and data.Topics covered:1. 4 Marketing Analytics Principles2. JMP Orientation3. Segmentation Concept Demo and Case4. Targeting Concept5. Choice Models Demo and Case6. Customer Lifetime Value7. Conjoint Concept Demo and Case8. Satisfaction Analytics Concept and Case 9. Response Models Concept and CaseIn MKTG 625, students undertake a several case studies focused on Û¢ Retail site location decisionsÛ¢ B2B segmentation in healthcareÛ¢ Customer acquisition in B2B, retailing and  technology productsÛ¢ Customer lifetime value in the hospitality businessÛ¢ New product development in technology, and  industrial manufacturingÛ¢ Satisfaction profit chains in the energy sectorÛ¢ Market response models in the media industry","['customer lifetime value', 'Satisfaction Analytics Concept', 'Segmentation Concept Demo', 'marketing analytics problems', 'Marketing Analytics Principles2', 'Conjoint Concept Demo', 'customer choice models', 'decisions\x89Û¢ B2B segmentation', 'various quantitative techniques', 'various marketing models', 'products\x89Û¢ Customer lifetime', 'Customer Lifetime Value7', 'popular statistical software', 'Market response models', 'market response models.Course', 'data analytic techniques', 'today\x89Ûªs data era', 'healthcare\x89Û¢ Customer acquisition', 'case studies', 'industrial manufacturing\x89Û¢ Satisfaction', 'real database/marketing engineering', '\x89Û¢ Retail site', 'New product development', 'customer segmentation', 'conjoint models', 'analytics opportunity', 'predictive models', 'process-driven manner', 'PC-based analysis', 'quantitative analyses', 'JMP Orientation3', 'CaseIn MKTG', '\x89ÛÏfirst principles\x89Û\x9d', 'media industry', 'profit chains', 'students', 'technology', 'datasets', 'SAS', 'retailing', 'variety', 'JMP/SAS', 'number', 'hands', 'Goals', 'strategy', 'firms', 'Concept5', 'learning', 'cases', 'data.Topics', 'Case4', 'location', 'Case6']","['Marketing', 'Scientific method', 'Statistics', 'Qualitative research', 'New product development', 'Market segmentation', 'Sales', 'Evaluation methods', 'Marketing strategy', 'Business-to-business', 'Product', 'Customer equity', 'Case study', 'Education', 'Customer lifetime value', 'Quantitative marketing research', 'Philosophy of language', 'Sociology', 'Logic', 'Consumer behaviour']",['database'],[],['SAS']
120,Practicum ,The students will learn:1. Understanding of self and others: Behavior assessment.2. Presence and presentation skills.3. Business writing.4. More on teams.5. Emotional intelligence.6. Leadership/fellowship.7. Constructive criticism.8. Peer review on capstone drafts with project coaches.9. Industry guest speakers--applying predictive modeling.,"['Industry guest speakers', 'capstone drafts', 'Constructive criticism.8', 'Emotional intelligence.6', 'predictive modeling', 'Peer review', 'Behavior assessment.2', 'Business writing.4', 'presentation skills.3', 'project coaches.9']","['Review', 'Construction', 'Predictive analytics', 'Scientific method']",['predictive modeling'],[],[]
121, Residency two: Capstone Update & Case Studies,1. Producing predictive models2. Work with live case studies,"['predictive models2', 'live case', 'Work', 'studies']","['Scientific method', 'Case study']",[],[],[]
122,Applied Analytics Using SAS Enterprise Guide ,"This course is an introduction to the general concepts and methodologies associated with Data Mining, Neural Networks, Machine Learning, and Analytics Modeling. Data Mining is the modeling and analysis of data, usually very large datasets, for decision making. Although several software packages used for Data Mining will be reviewed and compared, the primary concepts will be illustrated using SAS Enterprise Miner. Models discussed include neural networks; multiple and logistic regression; decision trees; and clustering algorithms.Topics:1. The data mining process2. Introduction to SAS Enterprise Miner3. Data collection, exploration and pre-processing4. Linear and logistic regression in Enterprise Miner5. High performance Enterprise Miner6. Comparing and evaluating big data models7. Machine Learning: Decision Trees8. Machine Learning: Random Forests9. Ensemble modeling10. Introduction to text analytics11. Document classification & sentiment analysis12. Topic analysis13. Machine Learning: Neural networks & Random Forests.","['data mining', 'neural networks', 'Machine Learning', 'logistic regression', 'SAS Enterprise Miner3', 'data mining process2', 'big data models7', 'decision making', 'decision trees', 'large datasets', 'Analytics Modeling', 'Decision Trees8', 'general concepts', 'software packages', 'Random Forests', 'Data collection', 'primary concepts', 'sentiment analysis12', 'Random Forests9', 'Topic analysis13', 'Enterprise Miner5', 'High performance', 'Enterprise Miner6', 'Document classification', 'introduction', 'methodologies', 'course', 'algorithms.Topics', 'Linear', 'modeling10']","['Data analysis', 'Machine learning', 'Statistical classification', 'Data mining', 'Decision tree learning', 'Artificial neural network', 'Logistic function', 'Decision theory', 'Neural network', 'Logistic regression', 'Decision trees', 'Predictive analytics', 'Cognition']","['Data Mining', 'Neural Networks', 'Linear', 'regression', 'big data', 'Machine Learning', 'Machine Learning', 'Ensemble', 'Machine Learning', 'Random Forests', 'Machine Learning', 'Modeling', 'Data Mining', 'Data Mining', 'regression', 'clustering']",[],"['SAS', 'SAS']"
123,Financial Accounting ,"This course will examine the internal uses of financial and operational information in planning, controlling, decision making, and performance evaluation in the global market. A specific emphasis will be placed on learning concepts pertaining to: cost management and organizational strategy; cost behaviors; product cost flows; forecasting, cost prediction, managerial incentives and budgeting; and managerial and segment performance evaluation.Topics discussed in ACCT 610 include1. Product costing methods2. Responsibility accounting3. Operational and capital budgeting4. Use of accounting metrics in executive   compensation contracts 5. Firm valuation6. Cost analysis for decision making7. Activity-based costing8. Balanced scorecards 9. Product and service pricingPrevious case studies have focused on:1. Financial Statement Analysis2. Product line go/no go decisions3. Profitability measurements of individual products in a   multi-product entity4. Budgeting including cash budgets and pro-form   financial statements5. Activity-based costing6. CRM systems and identification of profit potential of   individual customers and distribution channels7. Transfer pricing 8. Managerial control and incentives","['segment performance evaluation.Topics', 'pro-form   financial statements5', 'managerial incentives', 'executive   compensation contracts', 'Financial Statement Analysis2', 'service pricingPrevious case', 'Activity-based costing8', 'Activity-based costing6', 'Managerial control', 'operational information', 'product cost', 'cost behaviors', 'decision making', 'cost prediction', 'cost management', 'internal uses', 'global market', 'multi-product entity4', 'specific emphasis', 'organizational strategy', 'Responsibility accounting3', 'decision making7', 'Cost analysis', 'Firm valuation6', 'capital budgeting4', 'Product line', 'Profitability measurements', 'cash budgets', 'Transfer pricing', 'individual products', 'CRM systems', 'individual customers', 'profit potential', 'distribution channels7', 'ACCT', 'scorecards', 'metrics', 'forecasting', 'course', 'planning']","['Management', 'Marketing', 'Economics', 'Cost', 'Balanced scorecard', 'Control', 'Cost-benefit analysis', 'Risk', 'Costs', 'Cost accounting', 'Planning', 'Price', 'Project management', 'Organization', 'Forecasting', 'Pricing', 'Generally Accepted Accounting Principles', 'Psychology', 'Decision making', 'Budget', 'Specific Identification', 'Case study', 'Psychometrics', 'Profit']",[],[],[]
124,Practicum ,The student will learn:1. Cyber security2. Capstone work with project coaches3. Industry guest speakers--applying predictive modeling,"['Industry guest speakers', 'Capstone work', 'Cyber security2', 'predictive modeling', 'project coaches3', 'student']",['Predictive analytics'],['predictive modeling'],[],[]
125,Meth. in Time Series Anly. ,"Prepare time series data for model fitting. Identify whether a time series exhibits the following properties: stationarity vs trend and/or seasonality. Fit appropriate models to time series data from a wide variety of business settings.At the completion of the course, students will be able to:1. Prepare time series data for model fitting2. Identify whether a time series exhibits the   following properties:      a) Stationarity vs trend and/or        seasonality     b) Outliers and/or level shifts3. Fit appropriate models to time series data from   a wide variety of business settings6. Interpret the output from models for time series data7. Identify weaknesses in models for time series data   and formulate ways to overcome them 8. Make valid predictions of future values and draw   business conclusions on the basis of the fitted   models for time series data9. Recommend business actions on the basis of  these conclusionsTopic list:1. Introduction ÛÒ Autocorrelation and stationarity vs trend  and/or seasonality 2. Autoregressive (AR) models 3. Moving average (MA) models4. Autoregressive moving average (ARMA) models 5. Autoregressive integrated moving average (ARIMA)   models 6. Exponential smoothing7. Regression models with autocorrelated errors8. SAS Forecast Studio 9. Models for more than one time series   i. Transfer function models    ii. Multivariate time series modelsPast student group projects include:1. Based on point-of-sale grocery store sales data, forecast  weekly ground turkey sales by U.S. region.2. ARIMA models for theft and burglary rates3. Seasonal ARIMA models for Monthly Economic Value of   Mineral, Oil, and Gas Field Machinery Manufacturing4.Predicting cattle slaughter counts5. Seasonal ARIMA models for the number of social   security claims received by region6. Predicting Ready Mix Daily Sales for a large   metropolitan area7. Seasonal ARIMA models for average monthly energy   bill for a large metropolitan city.8. Predicting weekly candy sales across the US9. Transfer function models of global mean   temperature change as a function of   CO2 concentration levels","['time series', 'time series data', 'stationarity vs trend', 'Seasonal ARIMA models', 'Transfer function models', 'time series data7', 'time series data9', 'Multivariate time series', 'appropriate models', 'following properties', 'wide variety', 'average monthly energy', 'Introduction \x89ÛÒ Autocorrelation', 'store sales data', 'SAS Forecast Studio', 'ground turkey sales', 'weekly candy sales', 'large metropolitan city.8', 'modelsPast student group', 'CO2 concentration levels', 'Mix Daily Sales', 'Monthly Economic Value', 'Gas Field Machinery', 'large   metropolitan area7', 'social   security claims', 'global mean   temperature', 'fitted   models', 'Regression models', 'model fitting', 'business settings6', 'business conclusions', 'autocorrelated errors8', 'model fitting2', 'Exponential smoothing7', 'business actions', 'level shifts3', 'seasonality', 'valid predictions', 'burglary rates3', 'future values', 'U.S. region.2', 'Manufacturing4.Predicting cattle', 'Outliers', 'basis', 'weaknesses', 'course', 'students', 'completion', 'ways', 'models4', 'list', 'projects', 'US9', 'change', 'Oil', 'counts5']","['Time series', 'Time series analysis', 'Autoregressive moving average model', 'Autoregressive integrated moving average', 'Regression analysis', 'Moving average', 'Spectral density', 'Trend estimation', 'Statistics', 'Stationary process', 'Future', 'Exponential smoothing', 'Autoregressive conditional heteroskedasticity', 'Seasonality', 'Forecasting', 'Time series database', 'Lag operator', 'Prediction', 'Average', 'Infinite impulse response', 'Following', 'Transfer function', 'Autocorrelation', 'Futurology', 'Function', 'Fourier series', 'Autoregressive model']",['Regression'],[],['SAS']
126,Adv. Prog. using SAS ,"This course focuses on SAS programming in the Data step, including modifying variables, formats, and loops; various procedures, including sort, means, tabulate, and freq; creating graphs; debugging; the SAS/SQL language; macros; and optimization. Prerequisite: STAT 608 The Optimization Section primarily focuses on formulating and solving mathematical optimization using the SAS OPTMODEL procedure, from reading data to interpreting output and creating data sets. The course covers applications of linear programming, integer and mixed integer programming, and non-linear programming. Students will understand and undertake case studies. At the conclusion of the course students will be knowledgeable about optimization methodology and the use of the advanced SAS optimization capabilities.Course topics:1. Loops, Variable Types, Dates, Functions, Formats.   Importing and Exporting data SAS/SQL2. Macro language 3. Graphing Data 4. Creating HTML, PDF, RTF, and Excel output 5. Advanced data step features: BY group processing,   indexing, arrays, multi-dimensional arrays, and more 6. optimization and PROC OPTMODEL 7. Arrays and Index Sets/LP Models 8. Formatted Output/Dual Variables 9. Control Flow, Operators, & Model Updates 10. Network Problems/ILP and MILP Models 11. Binary Variables/Separable NLP Models 12. General NLP Models/Local Search","['SAS OPTMODEL procedure', 'SAS optimization capabilities.Course', 'mixed integer programming', 'data step', 'Variables/Separable NLP Models', 'data step features', 'NLP Models/Local Search', 'Index Sets/LP Models', 'SAS programming', 'multi-dimensional arrays', 'Optimization Section', 'mathematical optimization', 'data sets', 'Graphing Data', 'various procedures', 'non-linear programming', 'SAS/SQL language', 'data SAS/SQL2', 'optimization methodology', 'Output/Dual Variables', 'PROC OPTMODEL', 'linear programming', 'Macro language', 'case studies', 'Excel output', 'Variable Types', 'group processing', 'MILP Models', 'Control Flow', 'Model Updates', 'Network Problems/ILP', 'loops', 'freq', 'formats', 'students', 'Prerequisite', 'STAT', 'conclusion', 'debugging', 'sort', 'macros', 'graphs', 'RTF', 'indexing', 'applications', 'topics']","['Optimization', 'Operations research', 'Linear programming', 'Programming language', 'Algorithm', 'Nonlinear programming', 'Mathematics', 'Polytope', 'George Dantzig', 'Assembly language', 'C', 'Integer programming', 'Simplex algorithm', 'Mathematical optimization']","['programming', 'programming', 'programming', 'programming']",[],"['SAS', 'SAS', 'SAS']"
127,Directed Studies ,The student will learn:1. Industry guest speakers--applying predictive modeling.2. capstone project work sessions with project coach.,"['predictive modeling.2. capstone', 'Industry guest speakers', 'project work sessions', 'project coach']","['1990s American television series', 'Project management', 'Prediction interval']",[],[],[]
128, Residency Three: Capstone Project Presentations/Graduation,1. Capstone project employer and peer-presentations.2. Graduation,"['Capstone project employer', 'Graduation', '1.', 'peer-presentations.2']",[],[],[],[]
129,Spatial Statistics ,"Develop a strong understanding of spatial and spatio-temporal data analysis. Learn and understand the various empirical and graphical tools for understanding spatial and spatio-temporal data that arise in business applications.List of Topics:1. Introduction2. Auto correlation3. Stationary, isotropic random fields4. Variograms5. Kriging6. Estimation methods for covariance parameters7. Spatial regression8. Nonstationary models9. Spatio-temporal models10. Multivariate spatial modelsProjects:1. Modeling gasoline prices in large cities across the   United States2. Modeling real estate prices in King County, Washington","['spatio-temporal data', 'spatio-temporal data analysis', 'Multivariate spatial modelsProjects', 'isotropic random fields4', 'Spatio-temporal models10', 'Spatial regression8', 'real estate prices', 'covariance parameters7', 'graphical tools', 'strong understanding', 'business applications.List', 'Estimation methods', 'gasoline prices', 'Auto correlation3', 'Nonstationary models9', 'large cities', 'United States2', 'King County', 'Learn', 'Introduction2', 'Topics', 'Variograms5']","['Knowledge', 'City', 'Real estate', 'Variance', 'Statistics', 'Washington', 'Understanding', 'The Various', 'Scientific method', 'Data', 'Real estate pricing']","['Modeling', 'Modeling']",[],[]
130,Financial Modeling ,"Learn how to build sophisticated financial models that analyze the impact of proposed corporate projects, investments, and other strategic decisions on shareholder value. Master the basic finance theory that underlies valuation models.Throughout the class students will:1. Fundamental principles underlying all financial  models, including the concept of free cash flow,   the time value of money and net present value.2. The fundamentals of capital structure and   financing policy3. The weighted average cost of capital and adjusted   present value methods4. Building deterministic models for forecasting   financial statements and free cash flows5. Incorporating uncertainty and simulation techniques   into financial statement and free cash flow   forecasting models6. Fitting distributions for simulation of financial   time series and other stochastic processes7. Estimation of the cost of equity and equity capital,   as well as the weighted average cost of capital8. Incorporating real options into financial models9. Applications","['weighted average cost', 'free cash flow', 'sophisticated financial models', 'cash flow   forecasting', 'basic finance theory', 'free cash flows5', 'Building deterministic models', 'net present value.2', 'present value methods4', 'financial   time series', 'underlies valuation', 'shareholder value', 'strategic decisions', 'corporate projects', 'class students', 'Fundamental principles', 'financial statements', 'Fitting distributions', 'financial statement', 'financial models9', 'equity capital', 'time value', 'capital structure', 'stochastic processes7', 'financing policy3', 'real options', 'simulation techniques', 'uncertainty', 'Estimation', 'fundamentals', 'investments', 'impact', 'Master', 'money', 'concept']","['Finance', 'Corporate finance', 'Weighted average cost of capital', 'Generally Accepted Accounting Principles', 'Investment', 'Economics', 'Stock market', 'Discounted cash flow', 'Fundamental analysis', 'Capital structure', 'Bond', 'Net present value']","['simulation', 'simulation']",[],[]
131,Fund. of Bus. Prog. ,"The ISTM 601 course provides an opportunity to build upon the introductory Python coding experience gained in the first semester (ISTM 615). Students will explore various publically available Python code libraries that are useful to data science (e.g., Pandas, NumPy, SciKit-Learn, Seaborn, etc.) and learn how to apply them in their analytics work. Other potential topics include web scraping and machine learning. Students will complete a data analysis project by writing Pyton code.","['publically available Python', 'data analysis project', 'introductory Python', 'web scraping', 'code libraries', 'potential topics', 'machine learning', 'Pyton code', 'NumPy', 'Seaborn', 'Pandas', 'semester', 'ISTM', 'Students', 'analytics']","['Learning', 'Python', 'Knowledge', 'Education', 'Machine learning', 'Data analysis', 'C', 'Scientific method', 'NumPy', 'Functional programming', 'Java', 'Matplotlib', 'Energy', 'Python programming language', 'Code', 'Web scraping', 'World Wide Web']",['machine learning'],[],"['Python', 'Python', 'Pandas', 'NumPy', 'SciKit-Learn']"
132,Directed Studies ,The student will learn:1. Executive coaching sessions:     a) LinkedIn profiles.     b) Resumes for experienced professionals.     c) Managing your professional career.2. Final capstone presentation with graduate committee.3. Peer and employer capstone presentations.,"['employer capstone presentations', 'Final capstone presentation', 'Executive coaching sessions', 'LinkedIn profiles.', 'experienced professionals.', 'professional career.2', 'graduate committee.3']",['Management'],[],[],[]
